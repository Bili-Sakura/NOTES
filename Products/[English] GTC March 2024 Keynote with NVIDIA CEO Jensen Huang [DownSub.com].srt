1
00:00:00,000 --> 00:00:29,640
[Music]

2
00:00:29,640 --> 00:00:30,760
I am I am a

3
00:00:30,760 --> 00:00:44,260
Visionary Illuminating galaxies 
to witness the birth of [Music]

4
00:00:44,260 --> 00:00:50,880
stars and sharpening our understanding of extreme  

5
00:00:50,880 --> 00:01:03,200
weather [Music] events I am a helper 
guiding the blind through a crowded

6
00:01:03,200 --> 00:01:12,400
world I was thinking about running 
to the store and giving voice to  

7
00:01:12,400 --> 00:01:20,440
those who cannot speak to not make me laugh I am a

8
00:01:20,440 --> 00:01:29,920
Transformer harnessing gravity to 
store Renewable [Music] Power [Music]

9
00:01:34,240 --> 00:01:37,080
and Paving the way towards unlimited clean  

10
00:01:37,080 --> 00:01:48,000
energy for us [Music] all I am a 
[Music] trainer teaching robots to

11
00:01:48,000 --> 00:02:01,320
assist to watch out for 
[Music] danger and help save

12
00:02:01,320 --> 00:02:14,400
lives I am a Healer providing a 
new generation of cures and new  

13
00:02:14,400 --> 00:02:19,320
levels of patient care doctor that I am 
allergic to penicillin is it still okay  

14
00:02:19,320 --> 00:02:24,080
to take the medications definitely these 
antibiotics don't contain penicillin so  

15
00:02:24,080 --> 00:02:35,000
it's perfectly safe for you to take them I 
am a navigator [Music] generating virtual

16
00:02:35,000 --> 00:02:41,680
scenarios to let us safely explore the real

17
00:02:41,680 --> 00:02:49,200
world and understand every [Music]

18
00:02:49,200 --> 00:02:53,560
decision I even helped write the

19
00:02:53,560 --> 00:02:59,840
script breathe life into the words [Music]

20
00:03:13,400 --> 00:03:23,600
I am AI brought to life by Nvidia 
deep learning and Brilliant Minds

21
00:03:23,600 --> 00:03:29,760
everywhere

22
00:03:34,120 --> 00:03:54,440
please welcome to the stage Nvidia founder and CEO 
Jensen [Music] [Applause] [Music] Wong welcome to

23
00:03:54,440 --> 00:04:03,320
GTC I hope you realize this is not a

24
00:04:03,320 --> 00:04:12,480
concert you have arrived at 
a developers conference there  

25
00:04:12,480 --> 00:04:19,040
will be a lot of science described 
algorithms computer architecture

26
00:04:19,040 --> 00:04:35,560
mathematics I sensed a very heavy weight in the 
room all of a sudden almost like you were in  

27
00:04:35,560 --> 00:04:44,600
the wrong place no no conference in the world 
is there a great assembly of researchers from  

28
00:04:44,600 --> 00:04:53,080
such diverse fields of science from climatech to 
radio Sciences trying to figure out how to use AI  

29
00:04:53,080 --> 00:05:03,000
to robotically control MOS for Next Generation 6G 
radios robotic self-driving car s even artificial

30
00:05:03,000 --> 00:05:13,720
intelligence even artificial intelligence 
everybody's first I noticed a sense of relief  

31
00:05:13,720 --> 00:05:24,360
there all of all of a sudden also this conference 
is represented by some amazing companies this list  

32
00:05:24,360 --> 00:05:33,800
this is not the attendees these are the 
presentors and what's amazing is this if  

33
00:05:33,800 --> 00:05:41,760
you take away all of my friends close friends 
Michael Dell is sitting right there in the IT

34
00:05:41,760 --> 00:05:54,800
industry all of the friends I grew up with in 
the industry if you take away that list this is  

35
00:05:54,800 --> 00:06:02,480
what's amazing these are the presenters of the 
non it Industries using accelerated Computing  

36
00:06:02,480 --> 00:06:11,320
to solve problems that normal computers 
can't it's represented in life sciences  

37
00:06:11,320 --> 00:06:18,840
healthc Care genomics Transportation of 
course retail Logistics manufacturing

38
00:06:18,840 --> 00:06:27,440
industrial the gamut of Industries represented 
is truly amazing and you're not here to attend  

39
00:06:27,440 --> 00:06:34,080
only you're here to present to talk about 
your research $100 trillion dollar of the  

40
00:06:34,080 --> 00:06:38,800
world's Industries is represented in 
this room today this is absolutely

41
00:06:38,800 --> 00:06:51,760
amazing there is absolutely something 
happening there is something going on  

42
00:06:51,760 --> 00:06:59,200
the industry is being transformed not just ours 
because the computer industry the computer is  

43
00:06:59,200 --> 00:07:05,960
the single most important instrument of society 
today fundamental transformations in Computing  

44
00:07:05,960 --> 00:07:12,200
affects every industry but how did we start 
how did we get here I made a little cartoon  

45
00:07:12,200 --> 00:07:21,720
for you literally I drew this in one page 
this is nvidia's Journey started in 1993  

46
00:07:21,720 --> 00:07:28,480
this might be the rest of the talk 1993 this 
is our journey we were founded in 1993 there  

47
00:07:28,480 --> 00:07:34,000
are several important events that happen 
along the way I'll just highlight a few  

48
00:07:34,000 --> 00:07:40,240
in 2006 Cuda which has turned out to have been 
a revolutionary Computing model we thought it  

49
00:07:40,240 --> 00:07:44,840
was revolutionary then it was going to be an 
overnight success and almost 20 years later it

50
00:07:44,840 --> 00:07:50,200
happened we saw it

51
00:07:50,200 --> 00:07:54,720
coming two decades

52
00:07:54,720 --> 00:08:10,800
later in 2012 alexnet Ai and Cuda made first 
Contact in 2016 recognizing the importance  

53
00:08:10,800 --> 00:08:16,960
of this Computing model we invented a brand 
new type of computer we called the dgx one  

54
00:08:16,960 --> 00:08:24,000
170 Tera flops in this supercomputer eight 
gpus connected together for the very first  

55
00:08:24,000 --> 00:08:33,120
time I hand delivered the very first dgx-1 to 
a startup located in San Francisco called open

56
00:08:33,120 --> 00:08:51,440
AI dgx-1 was the world's first AI supercomputer 
remember 170 Tera flops 2017 the Transformer  

57
00:08:51,440 --> 00:08:58,960
arrived 2022 chat GPT capture the world's 
imag imaginations have people realize the  

58
00:08:58,960 --> 00:09:08,640
importance and the capabilities of artificial 
intelligence and 2023 generative AI emerged and  

59
00:09:08,640 --> 00:09:17,880
a new industry begins why why is a new industry 
because the software never existed before we are  

60
00:09:17,880 --> 00:09:24,720
now producing software using computers to write 
software producing software that never existed  

61
00:09:24,720 --> 00:09:31,560
before it is a brand new category it took share 
from nothing it's a brand new category and the  

62
00:09:31,560 --> 00:09:41,160
way you produce the software is unlike anything 
we've ever done before in data centers generating  

63
00:09:41,160 --> 00:09:53,360
tokens producing floating Point numbers at very 
large scale as if in the beginning of this last  

64
00:09:53,360 --> 00:10:00,720
Industrial Revolution when people realized 
that you would set up factories apply energy  

65
00:10:00,720 --> 00:10:09,160
to it and this invisible valuable thing called 
electricity came out AC generators and 100 years  

66
00:10:09,160 --> 00:10:18,400
later 200 years later we are now creating new 
types of electrons tokens using infrastructure  

67
00:10:18,400 --> 00:10:25,120
we call factories AI factories to generate this 
new incredibly valuable thing called artificial  

68
00:10:25,120 --> 00:10:32,000
intelligence a new industry has emerged well 
well we're going to talk about many things  

69
00:10:32,000 --> 00:10:37,240
about this new industry we're going to talk 
about how we're going to do Computing next  

70
00:10:37,240 --> 00:10:42,480
we're going to talk about the type of software 
that you build because of this new industry the  

71
00:10:42,480 --> 00:10:48,160
new software how you would think about this 
new software what about applications in this  

72
00:10:48,160 --> 00:10:55,480
new industry and then maybe what's next and 
how can we start preparing today for what is  

73
00:10:55,480 --> 00:11:04,640
about to come next well but before I start I 
want to show you the soul of Nvidia the soul  

74
00:11:04,640 --> 00:11:16,000
of our company at the intersection of computer 
Graphics physics and artificial intelligence  

75
00:11:16,000 --> 00:11:26,240
all intersecting inside a computer in Omniverse 
in a virtual world simulation everything we're  

76
00:11:26,240 --> 00:11:32,400
going to show you today literally everything 
we're going to show you today is a simulation  

77
00:11:32,400 --> 00:11:39,720
not animation it's only beautiful because it's 
physics the world is beautiful it's only amazing  

78
00:11:39,720 --> 00:11:45,200
because it's being animated with robotics it's 
being animated with artificial intelligence what  

79
00:11:45,200 --> 00:11:52,280
you're about to see all day it's completely 
generated completely simulated and Omniverse  

80
00:11:52,280 --> 00:11:59,240
and all of it what you're about to enjoy is the 
world's first concert where everything is homemade

81
00:12:05,640 --> 00:12:12,553
everything is homemade you're about to watch 
some home videos so sit back and enjoy [Music]

82
00:12:12,553 --> 00:12:12,560
[Music]

83
00:12:12,560 --> 00:12:29,400
yourself [Music]

84
00:12:29,400 --> 00:12:59,120
m

85
00:12:59,120 --> 00:12:59,120
[Music]

86
00:13:28,920 --> 00:13:29,080
what

87
00:13:29,080 --> 00:13:29,280
[Music]
0:13:29.120,1193:02:47.295
[Music]

88
00:13:29,280 --> 00:13:59,040
a

89
00:13:59,040 --> 00:13:59,040
[Music]

90
00:14:29,080 --> 00:14:43,780
[Music]

91
00:14:43,780 --> 00:14:58,480
[Music]

92
00:14:58,480 --> 00:14:59,120
God I love it

93
00:14:59,120 --> 00:15:11,120
Nvidia accelerated Computing has reached the 
Tipping Point general purpose Computing has  

94
00:15:11,120 --> 00:15:17,240
run out of steam we need another way of doing 
Computing so that we can continue to scale so  

95
00:15:17,240 --> 00:15:23,000
that we can continue to drive down the cost of 
computing so that we can continue to consume  

96
00:15:23,000 --> 00:15:30,720
more and more Computing while being sustainable 
accelerated Computing is a dramatic speed up over  

97
00:15:30,720 --> 00:15:38,400
general purpose Computing and in every single 
industry we engage and I'll show you many the  

98
00:15:38,400 --> 00:15:45,560
impact is dramatic but in no industry is a 
more important than our own the industry of  

99
00:15:45,560 --> 00:15:54,200
using simulation tools to create products in this 
industry it is not about driving down the cost of  

100
00:15:54,200 --> 00:15:59,880
computing it's about driving up the scale of 
computing we would like to be able to sim at  

101
00:15:59,880 --> 00:16:07,240
the entire product that we do completely 
in full Fidelity completely digitally in  

102
00:16:07,240 --> 00:16:15,440
essentially what we call digital twins we would 
like to design it build it simulate it operate it  

103
00:16:15,440 --> 00:16:24,440
completely digitally in order to do that we need 
to accelerate an entire industry and today I would  

104
00:16:24,440 --> 00:16:30,000
like to announce that we have some Partners who 
are joining us in this journey to accelerate their  

105
00:16:30,000 --> 00:16:39,040
entire ecosystem so that we can bring the world 
into accelerated Computing but there's a bonus  

106
00:16:39,040 --> 00:16:47,120
when you become accelerated your infrastructure 
is cou to gpus and when that happens it's exactly  

107
00:16:47,120 --> 00:16:55,080
the same infrastructure for generative Ai and 
so I'm just delighted to announce several very  

108
00:16:55,080 --> 00:17:00,280
important Partnerships there are some of the most 
important companies in the world and Anis does  

109
00:17:00,280 --> 00:17:05,560
engineering simulation for what the world makes 
we're partnering with them to Cuda accelerate the  

110
00:17:05,560 --> 00:17:13,000
Ansys ecosystem to connect Ansys to the Omniverse 
digital twin incredible the thing that's really  

111
00:17:13,000 --> 00:17:17,440
great is that the install base of media GPU 
accelerated systems are all over the world in  

112
00:17:17,440 --> 00:17:24,079
every cloud in every system all over Enterprises 
and so the app the applications they accelerate  

113
00:17:24,079 --> 00:17:29,680
will have a giant installed base to go serve end 
users will have amazing applications and of course  

114
00:17:29,680 --> 00:17:39,760
system makers and csps will have great customer 
demand synopsis synopsis is nvidia's literally  

115
00:17:39,760 --> 00:17:45,600
first software partner they were there in very 
first day of our company synopsis revolutionized  

116
00:17:45,600 --> 00:17:52,600
the chip industry with high level design we 
are going to Cuda accelerate synopsis we're  

117
00:17:52,600 --> 00:17:58,040
accelerating computational lithography one of 
the most important applications that nobody's  

118
00:17:58,040 --> 00:18:04,720
ever known about in order to make chips we have 
to push lithography to limit Nvidia has created  

119
00:18:04,720 --> 00:18:13,040
a library domain specific library that accelerates 
computational lithography incredibly once we can  

120
00:18:13,040 --> 00:18:18,840
accelerate and software Define all of tsmc who 
is announcing today that they're going to go into  

121
00:18:18,840 --> 00:18:25,200
production with Nvidia kitho once this software 
defined and accelerated the next step is to apply  

122
00:18:25,200 --> 00:18:32,920
generative AI to the future of semiconductor 
manufacturing push in Geometry even further  

123
00:18:32,920 --> 00:18:39,920
Cadence builds the world's essential Eda and SDA 
tools we also use Cadence between these three  

124
00:18:39,920 --> 00:18:46,800
companies ansis synopsis and Cadence we basically 
build Nvidia together we are cud accelerating  

125
00:18:46,800 --> 00:18:53,840
Cadence they're also building a supercomputer out 
of Nvidia gpus so that their customers could do  

126
00:18:53,840 --> 00:19:03,520
fluid Dynamic simulation at a 100 a thousand times 
scale basically a wind tunnel in real time Cadence  

127
00:19:03,520 --> 00:19:09,800
Millennium a supercomputer with Nvidia gpus inside 
a software company building supercomputers I love  

128
00:19:09,800 --> 00:19:18,720
seeing that building Cadence co-pilots together 
imagine a day when Cadence could synopsis ansis  

129
00:19:18,720 --> 00:19:26,680
tool providers would offer you AI co-pilots so 
that we have thousands and thousands of co-pilot  

130
00:19:26,680 --> 00:19:32,040
assistants helping us design chips Design Systems 
and we're also going to connect Cadence digital  

131
00:19:32,040 --> 00:19:39,360
twin platform to Omniverse as you could see the 
trend here we're accelerating the world's CAE Eda  

132
00:19:39,360 --> 00:19:45,040
and SDA so that we could create our future in 
digital Twins and we're going to connect them  

133
00:19:45,040 --> 00:19:52,080
all to Omniverse the fundamental operating 
system for future digital twins one of the  

134
00:19:52,080 --> 00:19:58,040
industries that benefited tremendously from scale 
and you know you all know this one very well large  

135
00:19:58,040 --> 00:20:06,080
language model basically after the Transformer 
was invented we were able to scale large language  

136
00:20:06,080 --> 00:20:12,760
models at incredible rates effectively doubling 
every six months now how is it possible that by  

137
00:20:12,760 --> 00:20:18,560
doubling every six months that we have grown 
the industry we have grown the computational  

138
00:20:18,560 --> 00:20:23,400
requirements so far and the reason for that 
is quite simply this if you double the size  

139
00:20:23,400 --> 00:20:28,320
of the model you double the size of your brain you 
need twice as much information to go fill it and  

140
00:20:28,320 --> 00:20:37,080
so every time you double your parameter count you 
also have to appropriately increase your training  

141
00:20:37,080 --> 00:20:45,360
token count the combination of those two numbers 
becomes the computation scale you have to support  

142
00:20:45,360 --> 00:20:52,400
the latest the state-of-the-art open AI model is 
approximately 1.8 trillion parameters 1.8 trillion  

143
00:20:52,400 --> 00:21:01,240
parameters required several trillion tokens to go 
train so so a few trillion parameters on the order  

144
00:21:01,240 --> 00:21:07,440
of a few trillion tokens on the order of when you 
multiply the two of them together approximately  

145
00:21:07,440 --> 00:21:16,720
30 40 50 billion quadrillion floating Point 
operations per second now we just have to do some  

146
00:21:16,720 --> 00:21:23,840
Co math right now just hang hang with me so you 
have 30 billion quadrillion a quadrillion is like  

147
00:21:23,840 --> 00:21:34,120
a paa and so if you had a PA flop GPU you would 
need 30 billion seconds to go compute to go train  

148
00:21:34,120 --> 00:21:41,760
that model 30 billion seconds is approximately 
1,000 years well 1,000 years it's worth

149
00:21:41,760 --> 00:21:49,600
it like to do it sooner but it's worth

150
00:21:49,600 --> 00:21:55,120
it which is usually my answer 
when most people tell me hey  

151
00:21:55,120 --> 00:21:59,040
how long how long's it going to take to 
do something 20 years how it it's worth

152
00:21:59,040 --> 00:22:03,280
it but can we do it next

153
00:22:03,280 --> 00:22:16,200
week and so 1,000 years 1,000 years so what 
we need what we need are bigger gpus we need  

154
00:22:16,200 --> 00:22:23,040
much much bigger gpus we recognized this early on 
and we realized that the answer is to put a whole  

155
00:22:23,040 --> 00:22:27,840
bunch of gpus together and of course innovate 
a whole bunch of things along the way like  

156
00:22:27,840 --> 00:22:33,720
inventing 10 censor cores advancing MV links so 
that we could create essentially virtually Giant  

157
00:22:33,720 --> 00:22:40,760
gpus and connecting them all together with amazing 
networks from a company called melanox infiniband  

158
00:22:40,760 --> 00:22:46,760
so that we could create these giant systems and so 
djx1 was our first version but it wasn't the last  

159
00:22:46,760 --> 00:22:55,840
we built we built supercomputers all the way all 
along the way in 2021 we had Seline 4500 gpus or  

160
00:22:55,840 --> 00:23:04,680
so and then in 2023 we built one of the largest AI 
supercomputers in the world it's just come online  

161
00:23:04,680 --> 00:23:11,760
EOS and as we're building these things we're 
trying to help the world build these things and in  

162
00:23:11,760 --> 00:23:16,760
order to help the world build these things we got 
to build them first we build the chips the systems  

163
00:23:16,760 --> 00:23:23,240
the networking all of the software necessary 
to do this you should see these systems imagine  

164
00:23:23,240 --> 00:23:28,440
writing a piece of software that runs across the 
entire system Distributing the computation across  

165
00:23:29,160 --> 00:23:37,560
thousands of gpus but inside are thousands of 
smaller gpus millions of gpus to distribute work  

166
00:23:37,560 --> 00:23:43,000
across all of that and to balance the workload so 
that you can get the most Energy Efficiency the  

167
00:23:43,000 --> 00:23:52,240
best computation time keep your cost down and so 
those those fundamental Innovations is what got us  

168
00:23:52,240 --> 00:24:03,240
here and here we are as we see the miracle of chat 
GPT emerg in front of us we also realize we have a  

169
00:24:03,240 --> 00:24:09,920
long ways to go we need even larger models we're 
going to train it with multimodality data not  

170
00:24:09,920 --> 00:24:14,600
just text on the internet but we're going to we're 
going to train it on texts and images and graphs  

171
00:24:14,600 --> 00:24:21,720
and charts and just as we learn watching TV and 
so there's going to be a whole bunch of watching  

172
00:24:21,720 --> 00:24:27,720
video so that these Mo models can be grounded in 
physics understands that an arm doesn't go through  

173
00:24:27,720 --> 00:24:35,320
a wall and so these models would have common 
sense by watching a lot of the world's video  

174
00:24:35,320 --> 00:24:40,960
combined with a lot of the world's languages it'll 
use things like synthetic data generation just as  

175
00:24:40,960 --> 00:24:46,840
you and I do when we try to learn we might use 
our imagination to simulate how it's going to  

176
00:24:46,840 --> 00:24:51,960
end up just as I did when I Was preparing for 
this keynote I was simulating it all along the

177
00:24:51,960 --> 00:24:58,480
way I hope it's going to turn 
out as well as I had it in my

178
00:24:58,480 --> 00:25:11,080
head as I was simulating how this keynote was 
going to turn out somebody did say that another  

179
00:25:11,080 --> 00:25:19,160
performer did her performance completely on 
a treadmill so that she could be in shape to  

180
00:25:19,160 --> 00:25:28,720
deliver it with full energy I I didn't do that if 
I get a l wind at about 10 minutes into this you  

181
00:25:28,720 --> 00:25:36,880
know what happened and so so where were we we're 
sitting here using synthetic data generation we're  

182
00:25:36,880 --> 00:25:41,120
going to use reinforcement learning we're going 
to practice it in our mind we're going to have ai  

183
00:25:41,120 --> 00:25:47,000
working with AI training each other just like 
student teacher Debaters all of that is going  

184
00:25:47,000 --> 00:25:50,800
to increase the size of our model it's going 
to increase the amount of the amount of data  

185
00:25:50,800 --> 00:25:59,080
that we have and we're going to have to build 
even bigger gpus Hopper is fantastic but we  

186
00:25:59,080 --> 00:26:10,960
need bigger gpus and so ladies and gentlemen I 
would like to introduce you to a very very big

187
00:26:10,960 --> 00:26:17,520
[Applause]

188
00:26:17,520 --> 00:26:33,840
GPU named after David Blackwell math 
ician game theorists probability we  

189
00:26:33,840 --> 00:26:40,080
thought it was a perfect per per perfect 
name black wealth ladies and gentlemen enjoy

190
00:26:40,080 --> 00:26:58,240
this

191
00:27:39,800 --> 00:27:58,120
the

192
00:28:51,400 --> 00:28:58,040
com

193
00:28:58,040 --> 00:29:22,680
[Applause] Blackwell is not a chip Blackwell 
is the name of a platform uh people think we  

194
00:29:22,680 --> 00:29:32,040
make gpus and and we do but gpus don't look 
the way they used to here here's the here's  

195
00:29:32,040 --> 00:29:38,400
the here's the the if you will the heart 
of the blackw system and this inside the  

196
00:29:38,400 --> 00:29:45,240
company is not called Blackwell it's 
just the number and um uh this this  

197
00:29:45,240 --> 00:29:50,200
is Blackwell sitting next to oh this is the 
most advanced GPU in the world in production

198
00:29:50,200 --> 00:30:02,120
today this is Hopper this is Hopper 
Hopper changed the world this is

199
00:30:02,120 --> 00:30:12,920
Blackwell it's okay

200
00:30:12,920 --> 00:30:32,960
Hopper you're you're very good good good boy 
well good girl 208 billion transistors and so  

201
00:30:32,960 --> 00:30:39,160
so you could see you I can see that there's a 
small line between two dyes this is the first  

202
00:30:39,160 --> 00:30:45,120
time two dieses have abutted like this together 
in such a way that the two chip the two dieses  

203
00:30:45,120 --> 00:30:51,760
think it's one chip there's 10 terabytes of 
data between it 10 terabytes per second so  

204
00:30:51,760 --> 00:30:57,640
that these two these two sides of the Blackwell 
Chip have no clue which side they're on there's  

205
00:30:57,640 --> 00:31:05,480
no memory locality issues no cach issues it's 
just one giant chip and so uh when we were  

206
00:31:05,480 --> 00:31:11,000
told that Blackwell's Ambitions were beyond 
the limits of physics uh the engineer said  

207
00:31:11,000 --> 00:31:18,960
so what and so this is what what happened and 
so this is the Blackwell chip and it goes into  

208
00:31:18,960 --> 00:31:27,040
two types of systems the first one is form fit 
function compatible to Hopper and so you slide  

209
00:31:27,040 --> 00:31:32,040
all Hopper and you push in Blackwell that's the 
reason why one of the challenges of ramping is  

210
00:31:32,040 --> 00:31:37,720
going to be so efficient there are installations 
of Hoppers all over the world and they could be  

211
00:31:37,720 --> 00:31:42,920
they could be you know the same infrastructure 
same design the power the electricity The  

212
00:31:42,920 --> 00:31:51,160
Thermals the software identical push it right 
back and so this is a hopper version for the  

213
00:31:51,160 --> 00:31:58,240
current hgx configuration and this is what 
the other the second Hopper looks like this  

214
00:31:58,240 --> 00:32:06,120
now this is a prototype board and um Janine 
could I just borrow ladies and gentlemen Jan

215
00:32:06,120 --> 00:32:17,000
Paul and so this this is the this is 
a fully functioning board and I just  

216
00:32:17,000 --> 00:32:23,120
be careful here this right here is I don't know10

217
00:32:23,120 --> 00:32:29,800
billion the second one's

218
00:32:29,800 --> 00:32:38,440
five it gets cheaper after that so 
any customers in the audience it's

219
00:32:38,440 --> 00:32:47,640
okay all right but this is this one's quite 
expensive this is to bring up board and um  

220
00:32:47,640 --> 00:32:51,840
and the the way it's going to go to production 
is like this one here okay and so you're going  

221
00:32:51,840 --> 00:32:59,960
to take take this it has two blackw Dy two two 
blackw chips and four Blackwell dies connected  

222
00:32:59,960 --> 00:33:06,960
to a Grace CPU the grace CPU has a super 
fast chipto chip link what's amazing is this  

223
00:33:06,960 --> 00:33:14,600
computer is the first of its kind where this much 
computation first of all fits into this small of  

224
00:33:14,600 --> 00:33:21,200
a place second it's memory coherent they feel 
like they're just one big happy family working  

225
00:33:21,200 --> 00:33:28,480
on one application together and so everything 
is coherent within it um the just the amount  

226
00:33:28,480 --> 00:33:34,240
of you know you saw the numbers there's a lot 
of terabytes this and terabytes that's um but  

227
00:33:34,240 --> 00:33:41,320
this is this is a miracle this is a this let's see 
what are some of the things on here uh there's um  

228
00:33:41,320 --> 00:33:53,640
uh MV link on top PCI Express on the bottom on 
on uh your which one is mine and your left one  

229
00:33:53,640 --> 00:34:00,520
of them it doesn't matter uh one of them one 
of them is a CPU chipto chip link is my left  

230
00:34:00,520 --> 00:34:06,400
or your depending on which side I was just I was 
trying to sort that out and I just kind of doesn't

231
00:34:06,400 --> 00:34:13,480
matter hopefully it comes plugged in

232
00:34:13,480 --> 00:34:21,960
so okay so this is the grace Blackwell

233
00:34:21,960 --> 00:34:27,720
system

234
00:34:31,960 --> 00:34:32,360
but there's

235
00:34:32,360 --> 00:34:41,159
more so it turns out it turns out all of the 
specs is fantastic but we need a whole lot of  

236
00:34:41,159 --> 00:34:48,599
new features uh in order to push the limits 
Beyond if you will the limits of physics we  

237
00:34:48,600 --> 00:34:53,719
would like to always get a lot more X factors and 
so one of the things that we did was We Invented  

238
00:34:53,719 --> 00:34:59,280
another Transformer engine another Transformer 
engine the second generation it has the ability  

239
00:34:59,280 --> 00:35:10,280
to dynamically and automatically rescale and 
recas numerical formats to a lower Precision  

240
00:35:10,280 --> 00:35:16,400
whenever it can remember artificial intelligence 
is about probability and so you kind of have you  

241
00:35:16,400 --> 00:35:22,840
know 1.7 approximately 1.7 time approximately 
1.4 to be approximately something else does  

242
00:35:22,840 --> 00:35:29,800
that make sense and so so the the ability for 
the mathematics to retain the Precision and the  

243
00:35:29,800 --> 00:35:36,720
range necessary in that particular stage of the 
pipeline super important and so this is it's not  

244
00:35:36,720 --> 00:35:42,040
just about the fact that we designed a smaller ALU 
it's not quite the world's not quite that simple  

245
00:35:42,040 --> 00:35:51,120
you've got to figure out when you can use that 
across a computation that is thousands of gpus  

246
00:35:51,120 --> 00:35:57,160
it's running for weeks and weeks on weeks and you 
want to make sure that the the uh uh the training  

247
00:35:57,160 --> 00:36:02,640
job is going going to converge and so this new 
Transformer engine we have a fifth generation MV  

248
00:36:02,640 --> 00:36:10,760
link it's now twice as fast as Hopper but very 
importantly it has computation in the network  

249
00:36:10,760 --> 00:36:14,600
and the reason for that is because when you 
have so many different gpus working together  

250
00:36:14,600 --> 00:36:20,120
we have to share our information with each other 
we have to synchronize and update each other and  

251
00:36:20,120 --> 00:36:25,880
every so often we have to reduce the partial 
products and then rebroadcast out the partial  

252
00:36:25,880 --> 00:36:30,080
products the sum of the partial products back to 
everybody else and so there's a lot of what is  

253
00:36:30,080 --> 00:36:35,800
called all reduce and all to all and all gather 
it's all part of this area of synchronization  

254
00:36:35,800 --> 00:36:41,840
and collectives so that we can have gpus working 
with each other having extraordinarily fast links  

255
00:36:41,840 --> 00:36:48,360
and being able to do mathematics right in the 
network allows us to essentially amplify even  

256
00:36:48,360 --> 00:36:53,760
further so even though it's 1.8 terabytes per 
second it's effectively higher than that and  

257
00:36:53,760 --> 00:37:01,920
so it's many times that of Hopper the likel 
Ood of a supercomputer running for weeks on  

258
00:37:01,920 --> 00:37:08,200
in is approximately zero and the reason for that 
is because there's so many components working at  

259
00:37:08,200 --> 00:37:14,680
the same time the statistic the probability of 
them working continuously is very low and so  

260
00:37:14,680 --> 00:37:19,920
we need to make sure that whenever there is a 
well we checkpoint and restart as often as we  

261
00:37:19,920 --> 00:37:29,400
can but if we have the ability to detect a weak 
chip or a weak note early we could retire it and  

262
00:37:29,400 --> 00:37:35,480
maybe swap in another processor that ability 
to keep the utilization of the supercomputer  

263
00:37:35,480 --> 00:37:44,680
High especially when you just spent $2 billion 
building it is super important and so we put in a  

264
00:37:44,680 --> 00:37:55,440
Ras engine a reliability engine that does 100% 
self test in system test of every single gate  

265
00:37:55,440 --> 00:38:02,440
every single bit of memory on the Blackwell 
chip and all the memory that's connected to  

266
00:38:02,440 --> 00:38:10,480
it it's almost as if we shipped with every 
single chip its own Advanced tester that we  

267
00:38:10,480 --> 00:38:15,680
CH test our chips with this is the first time 
we're doing this super excited about it secure

268
00:38:15,680 --> 00:38:33,160
AI only this conference do they clap for Ras the 
the uh secure AI uh obviously you've just spent  

269
00:38:33,160 --> 00:38:39,000
hundreds of millions of dollars creating a very 
important Ai and the the code the intelligence  

270
00:38:39,000 --> 00:38:43,960
of that AI is encoded in the parameters you 
want to make sure that on the one hand you  

271
00:38:43,960 --> 00:38:50,040
don't lose it on the other hand it doesn't get 
contaminated and so we now have the ability to  

272
00:38:50,040 --> 00:39:00,840
encrypt data of course at rest but also in transit 
and while it's being computed it's all encrypted  

273
00:39:00,840 --> 00:39:05,720
and so we now have the ability to encrypt and 
transmission and when we're Computing it it is  

274
00:39:05,720 --> 00:39:11,760
in a trusted trusted environment trusted 
uh engine environment and the last thing  

275
00:39:11,760 --> 00:39:19,240
is decompression moving data in and out of these 
nodes when the compute is so fast becomes really  

276
00:39:19,240 --> 00:39:27,120
essential and so we've put in a high linee speed 
compression engine and effectively moves data 20  

277
00:39:27,120 --> 00:39:32,560
times times faster in and out of these computers 
these computers are are so powerful and there's  

278
00:39:32,560 --> 00:39:38,000
such a large investment the last thing we want 
to do is have them be idle and so all of these  

279
00:39:38,000 --> 00:39:48,920
capabilities are intended to keep Blackwell 
fed and as busy as possible overall compared  

280
00:39:48,920 --> 00:39:57,720
to Hopper it is two and a half times two and 
a half times the fp8 performance for training  

281
00:39:57,720 --> 00:40:04,800
per chip it is ALS it also has this new format 
called fp6 so that even though the computation  

282
00:40:04,800 --> 00:40:11,520
speed is the same the bandwidth that's Amplified 
because of the memory the amount of parameters  

283
00:40:11,520 --> 00:40:17,360
you can store in the memory is now Amplified 
fp4 effectively doubles the throughput this  

284
00:40:17,360 --> 00:40:24,360
is vitally important for inference one of the 
things that that um is becoming very clear is  

285
00:40:24,360 --> 00:40:31,200
that whenever you use a computer with AI on the 
other side when you're chatting with the chatbot  

286
00:40:31,200 --> 00:40:41,040
when you're asking it to uh review or make an 
image remember in the back is a GPU generating  

287
00:40:41,040 --> 00:40:50,240
tokens some people call it inference but it's more 
appropriately generation the way that Computing  

288
00:40:50,240 --> 00:40:56,040
is done in the past was retrieval you would 
grab your phone you would touch something um  

289
00:40:56,040 --> 00:41:02,000
some signals go off basically an email goes off 
to some storage somewhere there's pre-recorded  

290
00:41:02,000 --> 00:41:07,360
content somebody wrote a story or somebody made 
an image or somebody recorded a video that record  

291
00:41:07,360 --> 00:41:12,960
pre-recorded content is then streamed back to 
the phone and recomposed in a way based on a  

292
00:41:12,960 --> 00:41:20,760
recommender system to present the information to 
you you know that in the future the vast majority  

293
00:41:20,760 --> 00:41:25,800
of that content will not be retrieved and the 
reason for that is because that was pre-recorded  

294
00:41:25,800 --> 00:41:30,440
by somebody who doesn't understand the context 
which is the reason why we have to retrieve so  

295
00:41:30,440 --> 00:41:37,240
much content if you can be working with an AI 
that understands the context who you are for  

296
00:41:37,240 --> 00:41:42,840
what reason you're fetching this information and 
produces the information for you just the way you  

297
00:41:42,840 --> 00:41:49,840
like it the amount of energy we save the amount of 
networking bandwidth we save the amount of waste  

298
00:41:49,840 --> 00:41:56,680
of time we save will be tremendous the future 
is generative which is the reason why we call  

299
00:41:56,680 --> 00:42:03,400
it generative AI which is the reason why this 
is a brand new industry the way we compute is  

300
00:42:03,400 --> 00:42:11,040
fundamentally different we created a processor 
for the generative AI era and one of the most  

301
00:42:11,040 --> 00:42:20,920
important parts of it is content token generation 
we call it this format is fp4 well that's a lot  

302
00:42:20,920 --> 00:42:32,360
of computation 5x the Gen token generation 5x 
the inference capability of Hopper seems like

303
00:42:32,360 --> 00:42:43,480
enough but why stop there the answer is it's 
not enough and I'm going to show you why I'm  

304
00:42:43,480 --> 00:42:49,640
going to show you why and so we would like to 
have a bigger GPU even bigger than this one and  

305
00:42:49,640 --> 00:42:57,400
so we decided to scale it and notice but first 
let me just tell you how we've scaled over the  

306
00:42:57,400 --> 00:43:04,280
course of the last eight years we've increased 
computation by 1,000 times8 years 1,000 times  

307
00:43:04,280 --> 00:43:12,720
remember back in the good old days of Moore's Law 
it was 2x well 5x every what 10 10x every 5 years  

308
00:43:12,720 --> 00:43:19,560
that's easier easiest math 10x every 5 years 
a 100 times every 10 years 100 times every 10  

309
00:43:19,560 --> 00:43:30,000
years at the in the middle in the hey days of the 
PC Revolution one 100 times every 10 years in the  

310
00:43:30,000 --> 00:43:37,560
last 8 years we've gone 1,000 times we have 
two more years to go and so that puts it in

311
00:43:37,560 --> 00:43:46,920
perspective the rate at which we're advancing 
Computing is insane and it's still not fast  

312
00:43:46,920 --> 00:43:54,760
enough so we built another chip this chip 
is just an incredible chip we call it the  

313
00:43:54,760 --> 00:44:01,840
Envy link switch it's 50 billion transistors 
it's almost the size of Hopper all by itself  

314
00:44:01,840 --> 00:44:11,800
this switch ship has four MV links in it 
each 1.8 terabytes per second and and it  

315
00:44:11,800 --> 00:44:18,360
has computation in as I mentioned what is 
this chip for if we were to build such a  

316
00:44:18,360 --> 00:44:28,960
chip we can have every single GPU talk to every 
other GPU at full speed at the same time that's

317
00:44:28,960 --> 00:44:44,120
insane it doesn't even make sense but if you could 
do that if you can find a way to do that and build  

318
00:44:44,120 --> 00:44:52,520
a system to do that that's cost effective that's 
cost effective how incredible would it be that we  

319
00:44:52,520 --> 00:45:02,480
could have all these gpus connect over a coherent 
link so that they effectively are one giant GPU  

320
00:45:02,480 --> 00:45:06,400
well one of one of the Great Inventions in 
order to make a cost effective is that this  

321
00:45:06,400 --> 00:45:13,800
chip has to drive copper directly the seres of 
this chip is is just a phenomenal invention so  

322
00:45:13,800 --> 00:45:19,680
that we could do direct drive to copper and as 
a result you can build a system that looks like

323
00:45:19,680 --> 00:45:26,960
this

324
00:45:30,240 --> 00:45:39,200
now this system this system is kind of 
insane this is one dgx this is what a dgx  

325
00:45:39,200 --> 00:45:46,480
looks like now remember just six years ago 
it was pretty heavy but I was able to lift

326
00:45:46,480 --> 00:45:56,160
it I delivered the uh the uh first djx1 to 
open Ai and and the researchers there it's  

327
00:45:56,160 --> 00:46:02,720
on you know the pictures are on the internet 
and uh uh and we all autographed it uh and  

328
00:46:02,720 --> 00:46:08,280
um uh if you come to my office it's autographed 
there is really beautiful and but but you could  

329
00:46:08,280 --> 00:46:18,320
lift it uh this dgx this dgx that djx by 
the way was 170 teraflops if you're not  

330
00:46:18,320 --> 00:46:27,160
familiar with the numbering system that's 
0.17 pedop flops so this is 720 the first  

331
00:46:27,160 --> 00:46:32,440
one I delivered to open AI was 0.17 you 
could round it up to 0.2 won't make any  

332
00:46:32,440 --> 00:46:41,120
difference but and back then was like wow you 
know 30 more teraflops and so this is now 720  

333
00:46:41,120 --> 00:46:47,640
pedop flops almost an exal flop for training and 
the world's first one exal flops machine in one

334
00:46:47,640 --> 00:47:00,880
rack just so you know there are only a 
couple two three exop flops machines on  

335
00:47:00,880 --> 00:47:08,160
the planet as we speak and so this 
is an exop flops AI system in one  

336
00:47:08,160 --> 00:47:10,480
single rack well let's take a look at the back of

337
00:47:10,480 --> 00:47:19,200
it so this is what makes it possible 
that's the back that's the that's  

338
00:47:19,200 --> 00:47:27,240
the back the dgx MV link spine 130 
terabytes per second goes through  

339
00:47:27,240 --> 00:47:31,560
the back of that chassis that is more 
than the aggregate bandwidth of the

340
00:47:31,560 --> 00:47:48,360
internet so we we could basically send everything 
to everybody within a second and so so we we have  

341
00:47:48,360 --> 00:47:57,280
5,000 cables 5,000 mvlink cables in total 2 miles 
now this is the amazing thing if we had to use  

342
00:47:57,280 --> 00:48:02,360
Optics we would have had to use transceivers 
and retim and those transceivers and reers  

343
00:48:02,360 --> 00:48:12,160
alone would have cost 20,000 watts 2 kilowatts 
of just transceivers alone just to drive the  

344
00:48:12,160 --> 00:48:19,040
mvlink spine as a result we did it completely 
for free over mvlink switch and we were able  

345
00:48:19,040 --> 00:48:25,720
to save the 20 kilow for computation this entire 
rack is 120 kilowatts so that 20 kilowatts makes  

346
00:48:25,720 --> 00:48:33,000
a huge difference it's liquid cooled what 
goes in is 25° C about room temperature  

347
00:48:33,000 --> 00:48:41,280
what comes out is 45°c about your jacuzzi so room 
temperature goes in jacuzzi comes out 2 liters per

348
00:48:41,280 --> 00:48:51,480
second we could we could sell a

349
00:48:51,480 --> 00:49:05,480
peripheral 600,000 Parts somebody used to say 
you know you guys make gpus and we do but this  

350
00:49:05,480 --> 00:49:11,760
is what a GPU looks like to me when somebody 
says GPU I see this two years ago when I saw  

351
00:49:11,760 --> 00:49:25,800
a GPU was the hgx it was 70 lb 35,000 Parts our 
gpus now are 600,000 parts and 3,000 lb 3,000 lb  

352
00:49:25,800 --> 00:49:34,960
3,000 lb that's kind of like the weight of a you 
know Carbon Fiber Ferrari I don't know if that's  

353
00:49:34,960 --> 00:49:44,000
useful metric but everybody's going I feel it I 
feel it I get it I get that now that you mention  

354
00:49:44,000 --> 00:49:52,360
that I feel it I don't know what's 3,000 lb okay 
so 3,000 lb ton and a half so it's not quite an  

355
00:49:52,360 --> 00:49:59,160
elephant so this is what a dgx looks like now 
let's see what it looks like in operation okay  

356
00:49:59,160 --> 00:50:03,320
let's imagine what is what how do we put this 
to work and what does that mean well if you  

357
00:50:03,320 --> 00:50:11,680
were to train a GPT model 1.8 trillion parameter 
model it took it took about apparently about you  

358
00:50:11,680 --> 00:50:17,600
know 3 to 5 months or so uh with 25,000 amp 
uh if we were to do it with hopper it would  

359
00:50:17,600 --> 00:50:23,200
probably take something like 8,000 gpus and 
it would consume 15 megawatts 8,000 gpus on  

360
00:50:23,200 --> 00:50:29,000
15 megawatts it would take 90 days about 3 months 
and that would allows you to train something that  

361
00:50:29,000 --> 00:50:36,960
is you know this groundbreaking AI model and 
this is obviously not as expensive as as um  

362
00:50:36,960 --> 00:50:42,040
as anybody would think but it's 8,000 8,000 
gpus it's still a lot of money and so 8,000  

363
00:50:42,040 --> 00:50:51,600
gpus 15 megawatts if you were to use Blackwell 
to do this it would only take 2,000 gpus 2,000  

364
00:50:51,600 --> 00:51:00,160
gpus same 90 days but this is the amazing part 
only 4 me GS of power so from 15 yeah that's

365
00:51:00,160 --> 00:51:10,960
right and that's and that's our goal our goal 
is to continuously drive down the cost and the  

366
00:51:10,960 --> 00:51:15,520
energy they're directly proportional to each other 
cost and energy associated with the Computing so  

367
00:51:15,520 --> 00:51:20,640
that we can continue to expand and scale up the 
computation that we have to do to train the Next  

368
00:51:20,640 --> 00:51:29,760
Generation models well this is training inference 
or generation is vitally important going forward  

369
00:51:29,760 --> 00:51:34,000
you know probably some half of the time that 
Nvidia gpus are in the cloud these days it's  

370
00:51:34,000 --> 00:51:39,000
being used for token generation you know they're 
either doing co-pilot this or chat you know chat  

371
00:51:39,000 --> 00:51:43,560
GPT that or um all these different models that 
are being used when you're interacting with it  

372
00:51:43,560 --> 00:51:49,720
or generating IM generating images or generating 
videos generating proteins generating chemicals  

373
00:51:49,720 --> 00:51:55,640
there's a bunch of gener generation going on 
all of that is B in the category of computing  

374
00:51:55,640 --> 00:52:01,680
we call inference but inference is extremely 
hard for large language models because these  

375
00:52:01,680 --> 00:52:06,200
large language models have several properties 
one they're very large and so it doesn't fit on  

376
00:52:06,200 --> 00:52:14,320
one GPU this is Imagine imagine Excel doesn't fit 
on one GPU you know and imagine some application  

377
00:52:14,320 --> 00:52:18,320
you're running on a daily basis doesn't run 
doesn't fit on one computer like a video game  

378
00:52:18,320 --> 00:52:25,480
doesn't fit on one computer and most in fact 
do and many times in the past in hyperscale  

379
00:52:25,480 --> 00:52:29,640
Computing many applic applications for many 
people fit on the same computer and now all  

380
00:52:29,640 --> 00:52:35,560
of a sudden this one inference application where 
you're interacting with this chatbot that chatbot  

381
00:52:35,560 --> 00:52:42,200
requires a supercomputer in the back to run it 
and that's the future the future is generative  

382
00:52:42,200 --> 00:52:47,840
with these chatbots and these chatbots are 
trillions of tokens trillions of parameters  

383
00:52:47,840 --> 00:52:56,480
and they have to generate tokens at interactive 
rates now what does that mean well uh three to  

384
00:52:56,480 --> 00:53:06,440
tokens is about a word I you know the the uh 
you know space the final frontier these are the  

385
00:53:06,440 --> 00:53:13,840
adventures that's like that's like 80 tokens 
okay I don't know if that's useful to you and

386
00:53:13,840 --> 00:53:19,640
so you know the art of communications is  

387
00:53:19,640 --> 00:53:26,440
is selecting good an good analogies 
yeah this is this is not going well

388
00:53:28,840 --> 00:53:34,680
every I don't know what he's talking about 
never seen Star Trek and so and so so here  

389
00:53:34,680 --> 00:53:37,960
we are we're trying to generate these tokens 
when you're interacting with it you're hoping  

390
00:53:37,960 --> 00:53:42,240
that the tokens come back to you as quickly as 
possible and as quickly as you can read it and  

391
00:53:42,240 --> 00:53:47,400
so the ability for Generation tokens is really 
important you have to paralyze the work of this  

392
00:53:47,400 --> 00:53:52,520
model across many many gpus so that you could 
achieve several things one on the one hand you  

393
00:53:52,520 --> 00:54:00,040
would like throughput because that throughput 
reduces the cost the overall cost per token of  

394
00:54:00,040 --> 00:54:07,520
uh generating so your throughput dictates the cost 
of of uh delivering the service on the other hand  

395
00:54:07,520 --> 00:54:13,080
you have another interactive rate which is another 
tokens per second where it's about per user and  

396
00:54:13,080 --> 00:54:19,160
that has everything to do with quality of service 
and so these two things um uh compete against each  

397
00:54:19,160 --> 00:54:24,760
other and we have to find a way to distribute 
work across all of these different gpus and  

398
00:54:24,760 --> 00:54:30,000
paralyze it in a way that allows us to achieve 
both and it turns out the search search space  

399
00:54:30,000 --> 00:54:39,040
is enormous you know I told you there's going to 
be math involved and everybody's going oh dear I  

400
00:54:39,040 --> 00:54:45,440
heard some gasp just now when I put up that slide 
you know so so this this right here the the y axis  

401
00:54:45,440 --> 00:54:51,960
is tokens per second data center throughput the 
x- axis is tokens per second interactivity of the  

402
00:54:51,960 --> 00:54:58,040
person and notice the upper right is the best 
you want interactivity to be very High number  

403
00:54:58,040 --> 00:55:02,880
of tokens per second per user you want the tokens 
per second of per data center to be very high the  

404
00:55:02,880 --> 00:55:09,040
upper upper right is is terrific however it's very 
hard to do that and in order for us to search for  

405
00:55:09,040 --> 00:55:15,960
the best answer across every single one of those 
intersections XY coordinates okay so you just look  

406
00:55:15,960 --> 00:55:23,480
at every single XY coordinate all those blue dots 
came from some repartitioning of the software some  

407
00:55:23,480 --> 00:55:31,600
optimizing solution has to go and figure out what 
whether to use use tensor parallel expert parallel  

408
00:55:31,600 --> 00:55:38,640
pipeline parallel or data parallel and distribute 
this enormous model across all these G different  

409
00:55:38,640 --> 00:55:45,680
gpus and sustain performance that you need this 
exploration space would be impossible if not for  

410
00:55:45,680 --> 00:55:50,800
the programmability of nvidia's gpus and so we 
could because of Cuda because we have such Rich  

411
00:55:50,800 --> 00:55:57,840
ecosystem we could explore this universe and find 
that green roof line it turns out that green roof  

412
00:55:57,840 --> 00:56:07,040
line notice you got tp2 EPA dp4 it means two 
parall two uh tensor parallel tensor parallel  

413
00:56:07,040 --> 00:56:12,560
across two gpus expert parallels across eight data 
parallel across four notice on the other end you  

414
00:56:12,560 --> 00:56:19,440
got tensor parallel cross 4 and expert parallel 
across 16 the configuration the distribution of  

415
00:56:19,440 --> 00:56:25,880
that software it's a different different um 
runtime that would produce these different  

416
00:56:25,880 --> 00:56:31,600
results and you have to go discover that roof 
line well that's just one model and this is just  

417
00:56:31,600 --> 00:56:36,880
one configuration of a computer imagine all of the 
models being created around the world and all the  

418
00:56:36,880 --> 00:56:40,760
different different um uh configurations 
of of uh systems that are going to be

419
00:56:40,760 --> 00:56:50,560
available so now that you understand the 
basics let's take a look at inference of  

420
00:56:50,560 --> 00:56:58,560
Blackwell compared to Hopper and this is this 
is the extraordinary thing in one generation  

421
00:56:58,560 --> 00:57:05,440
because we created a system that's designed 
for trillion parameter gener generative AI the  

422
00:57:05,440 --> 00:57:13,560
inference capability of Blackwell is off the 
charts and in fact it is some 30 times Hopper

423
00:57:13,560 --> 00:57:26,440
y for large language models for large language 
models like Chad GPT and others like it the blue  

424
00:57:26,440 --> 00:57:31,640
line is Hopper I gave you imagine we didn't 
change the architecture of Hopper we just  

425
00:57:31,640 --> 00:57:41,080
made it a bigger chip we just used the latest you 
know greatest uh 10 terab you know terabytes per  

426
00:57:41,080 --> 00:57:46,320
second we connected the two chips together we got 
this giant 208 billion parameter chip how would we  

427
00:57:46,320 --> 00:57:52,360
have performed if nothing else changed and it 
turns out quite wonderfully quite wonderfully  

428
00:57:52,360 --> 00:57:59,200
and that's the purple line but not as great as it 
could be and and that's where the fp4 tensor core  

429
00:57:59,200 --> 00:58:05,920
the new Transformer engine and very importantly 
the MV link switch and the reason for that is  

430
00:58:05,920 --> 00:58:11,600
because all these gpus have to share the results 
partial products whenever they do all to all all  

431
00:58:11,600 --> 00:58:18,560
all gather whenever they communicate with each 
other that mvlink switch is communicating almost  

432
00:58:18,560 --> 00:58:27,120
10 times faster than what we could do in the 
past using the fastest networks Okay so Blackwell  

433
00:58:27,120 --> 00:58:35,960
is going to be just an amazing system for a 
generative Ai and in the future in the future  

434
00:58:35,960 --> 00:58:42,520
data centers are going to be thought of as I 
mentioned earlier as an AI Factory an AI Factory's  

435
00:58:42,520 --> 00:58:53,320
goal in life is to generate revenues generate 
in this case intelligence in this facility not  

436
00:58:53,320 --> 00:58:59,960
generating electricity as in AC generator but of 
the last Industrial Revolution and this Industrial  

437
00:58:59,960 --> 00:59:06,400
Revolution the generation of intelligence and 
so this ability is super super important the  

438
00:59:06,400 --> 00:59:13,400
excitement of Blackwell is really off the charts 
you know when we first when we first um uh you  

439
00:59:13,400 --> 00:59:17,880
know this this is a year and a half ago two years 
ago I guess two years ago when we first started to  

440
00:59:17,880 --> 00:59:24,960
to go to market with hopper you know we had the 
benefit of of uh two two uh two csps uh joined  

441
00:59:24,960 --> 00:59:32,840
us in a lunch and and we were you know delighted 
um and so we had two customers uh we have more

442
00:59:32,840 --> 00:59:51,920
now unbelievable excitement for Blackwell 
unbelievable excitement and there's a whole  

443
00:59:51,920 --> 00:59:56,680
bunch of different configurations of course I 
showed you the configurations that slide into  

444
00:59:56,680 --> 01:00:02,680
the hopper form factor so that's easy to upgrade 
I showed you examples that are liquid cooled that  

445
01:00:02,680 --> 01:00:09,080
are the extreme versions of it one entire rack 
that's that's uh connected by mvlink 72 uh we're  

446
01:00:09,080 --> 01:00:17,520
going to Blackwell is going to be ramping to the 
world's AI companies of which there are so many  

447
01:00:17,520 --> 01:00:28,240
now doing amazing work in different modalities the 
csps every CSP is geared up all the OEM and odms  

448
01:00:28,240 --> 01:00:36,640
Regional clouds Sovereign AIS and Telos all over 
the world are signing up to launch with Blackwell

449
01:00:36,640 --> 01:00:50,120
this Blackwell Blackwell would be the the the 
most successful product launch in our history  

450
01:00:50,120 --> 01:00:54,640
and so I can't wait wait to see that um I want 
to thank I want to thank some partners that that  

451
01:00:54,640 --> 01:01:00,000
are joining us in this uh AWS is gearing up for 
Blackwell they're uh they're going to build the  

452
01:01:00,000 --> 01:01:07,600
first uh GPU with secure AI they're uh building 
out a 222 exf flops system you know just now  

453
01:01:07,600 --> 01:01:12,880
when we animated uh just now the digital twin if 
you saw the the all of those clusters are coming  

454
01:01:12,880 --> 01:01:20,000
down by the way that is not just art that is a 
digital twin of what we're building that's how  

455
01:01:20,000 --> 01:01:25,040
big it's going to be besides infrastructure we're 
doing a lot of things together with AWS we're Cuda  

456
01:01:25,040 --> 01:01:32,040
accelerating stag maker AI we're Cuda accelerating 
Bedrock AI uh Amazon robotics is working with us  

457
01:01:32,040 --> 01:01:38,880
uh using Nvidia Omniverse and Isaac Sim AWS 
Health has Nvidia Health Integrated into it  

458
01:01:38,880 --> 01:01:45,920
so AWS has has really leaned into accelerated 
Computing uh Google is gearing up for Blackwell  

459
01:01:45,920 --> 01:01:53,440
gcp already has A1 100s h100s t4s l4s a whole 
Fleet of Nvidia Cuda gpus and they recently  

460
01:01:53,440 --> 01:01:59,800
announced the Gemma model that runs across all 
of it uh we're work working to optimize uh and  

461
01:01:59,800 --> 01:02:05,440
accelerate every aspect of gcp we're accelerating 
data proc which for data processing their data  

462
01:02:05,440 --> 01:02:13,200
processing engine Jax xlaa vertex Ai and mojoko 
for robotics so we're working with uh Google and  

463
01:02:13,200 --> 01:02:18,640
gcp across a whole bunch of initiatives uh Oracle 
is gearing up for black wellth Oracle is a great  

464
01:02:18,640 --> 01:02:23,960
partner of ours for Nvidia dgx cloud and we're 
also working together to accelerate something  

465
01:02:23,960 --> 01:02:30,480
that's really important to a lot of companies 
Oracle database Microsoft is accelerating and  

466
01:02:30,480 --> 01:02:35,760
Microsoft is gearing up for Blackwell Microsoft 
Nvidia has a wide- ranging partnership we're  

467
01:02:35,760 --> 01:02:40,760
accelerating Cuda accelerating all kinds of 
services when you when you chat obviously and  

468
01:02:40,760 --> 01:02:45,720
uh AI services that are in Microsoft Azure uh 
it's very very likely Nvidia is in the back uh  

469
01:02:45,720 --> 01:02:51,720
doing the inference and the token generation uh 
we built they built the largest Nvidia infiniband  

470
01:02:51,720 --> 01:02:56,760
supercomputer basically a digital twin of hours 
or a physical twin of hours uh we're bringing the  

471
01:02:56,760 --> 01:03:03,320
Nvidia ecosystem to Azure Nvidia djx cloud 
to Azure uh Nvidia Omniverse is now hosted  

472
01:03:03,320 --> 01:03:09,360
in Azure Nvidia Healthcare is an Azure and all of 
it is deeply integrated and deeply connected with  

473
01:03:09,360 --> 01:03:16,600
Microsoft fabric the whole industry is gearing up 
for Blackwell this is what I'm about to show you  

474
01:03:16,600 --> 01:03:23,480
most of the most of the the the uh uh uh scenes 
that you've seen so far of Blackwell are the are  

475
01:03:23,480 --> 01:03:31,680
the full Fidelity design of Blackwell everything 
in our company has a digital twin and in fact this  

476
01:03:31,680 --> 01:03:38,440
digital twin idea is it is really spreading and it 
it helps it helps companies build very complicated  

477
01:03:38,440 --> 01:03:46,600
things perfectly the first time and what could 
be more exciting than creating a digital twin to  

478
01:03:46,600 --> 01:03:51,640
build a computer that was built in a digital 
twin and so let me show you what wistron is

479
01:03:51,640 --> 01:04:00,880
doing to meet the demand for NVIDIA accelerated 
Computing widraw one of our leading manufacturing  

480
01:04:00,880 --> 01:04:07,080
Partners is building digital twins of Nvidia 
dgx and hgx factories using custom software  

481
01:04:07,080 --> 01:04:13,800
developed with Omniverse sdks and apis for 
their newest Factory wraw started with a  

482
01:04:13,800 --> 01:04:18,600
digital twin to virtually integrate their 
multi-ad and process simulation data into  

483
01:04:18,600 --> 01:04:24,720
a unified view testing and optimizing layouts 
in this physically accurate digital environment  

484
01:04:24,720 --> 01:04:31,400
increased worker efficency icy by 51% during 
construction the Omniverse digital twin was  

485
01:04:31,400 --> 01:04:37,040
used to verify that the physical build matched 
the digital plans identifying any discrepancies  

486
01:04:37,040 --> 01:04:42,880
early has helped avoid costly change orders and 
the results have been impressive using a digital  

487
01:04:42,880 --> 01:04:49,520
twin helped bring wion's Factory online in half 
the time just 2 and 1/2 months instead of five  

488
01:04:49,520 --> 01:04:54,760
in operation the Omniverse digital twin helps 
widraw rapidly Test new layouts to accommodate  

489
01:04:54,760 --> 01:05:00,080
new processes or improve operations in 
the existing space and monitor real-time  

490
01:05:00,080 --> 01:05:07,040
operations using live iot data from every machine 
on the production line which ultimately enabled  

491
01:05:07,040 --> 01:05:14,760
wion to reduce End to-end Cycle Times by 50% 
and defect rates by 40% with Nvidia Ai and  

492
01:05:14,760 --> 01:05:21,080
Omniverse nvidia's Global ecosystem of partners 
are building a new era of accelerated AI enabled

493
01:05:21,080 --> 01:05:25,640
[Music] digitalization

494
01:05:25,640 --> 01:05:25,640
[Applause]

495
01:05:31,800 --> 01:05:35,520
that's how we that's the way it's going 
to be in the future we're going to  

496
01:05:35,520 --> 01:05:39,760
manufacturing everything digitally first 
and then we'll manufacture it physically  

497
01:05:39,760 --> 01:05:46,600
people ask me how did it start what 
got you guys so excited what was it  

498
01:05:46,600 --> 01:05:56,640
that you saw that caused you to put it 
all in on this incredible idea and it's

499
01:05:56,640 --> 01:06:02,080
this hang on a

500
01:06:02,080 --> 01:06:09,160
second guys that was going to be such a

501
01:06:09,160 --> 01:06:14,160
moment that's what happens when you don't

502
01:06:14,160 --> 01:06:29,320
rehearse this as you know was first 
Contact 20 12 alexnet you put a cat  

503
01:06:29,320 --> 01:06:33,120
into this computer and it comes out and it says

504
01:06:33,120 --> 01:06:40,440
cat and we said oh my God this is going to change

505
01:06:40,440 --> 01:06:50,680
everything you take 1 million numbers you take 
one Million numbers across three channels RGB  

506
01:06:50,680 --> 01:06:57,680
these numbers make no sense to anybody you 
put it into this software and it compress  

507
01:06:57,680 --> 01:07:04,400
it dimensionally reduce it it reduces it from a 
million dimensions a million Dimensions it turns  

508
01:07:04,400 --> 01:07:15,000
it into three letters one vector one number 
and it's generalized you could have the cat  

509
01:07:15,000 --> 01:07:22,760
be different cats and and you could have it be the 
front of the cat and the back of the cat and you  

510
01:07:22,760 --> 01:07:33,120
look at this thing you say unbelievable you mean 
any cats yeah any cat and it was able to recognize  

511
01:07:33,120 --> 01:07:42,680
all these cats and we realized how it did it 
systematically structurally it's scalable how big  

512
01:07:42,680 --> 01:07:49,600
can you make it well how big do you want to make 
it and so we imagine that this is a completely  

513
01:07:49,600 --> 01:07:58,760
new way of writing software and now today as you 
know you could have you type in the word c a and  

514
01:07:58,760 --> 01:08:10,240
what comes out is a cat it went the other way am 
I right unbelievable how is it possible that's  

515
01:08:10,240 --> 01:08:17,120
right how is it possible you took three letters 
and you generated a million pixels from it and  

516
01:08:17,120 --> 01:08:25,440
it made sense well that's the miracle and here we 
are just literally 10 years later 10 years later  

517
01:08:26,120 --> 01:08:32,920
where we recognize textt we recognize images we 
recognize videos and sounds and images not only  

518
01:08:32,920 --> 01:08:38,399
do we recognize them we understand their meaning 
we understand the meaning of the text that's the  

519
01:08:38,399 --> 01:08:44,719
reason why it can chat with you it can summarize 
for you it understands the text it understood not  

520
01:08:44,720 --> 01:08:50,640
just recognizes the the English it understood the 
English it doesn't just recognize the pixels and  

521
01:08:50,640 --> 01:08:56,040
understood the pixels and you can you can even 
condition it between two modalities you can have  

522
01:08:56,040 --> 01:09:02,120
language condition image and generate all kinds 
of interesting things well if you can understand  

523
01:09:02,120 --> 01:09:07,319
these things what else can you understand 
that you've digitized the reason why we  

524
01:09:07,319 --> 01:09:12,239
started with text and you know images is because 
we digitized those but what else have we digitized  

525
01:09:12,240 --> 01:09:20,319
well it turns out we digitized a lot of things 
proteins and genes and brain waves anything you  

526
01:09:20,319 --> 01:09:24,879
can digitize so long as there's structure we can 
probably learn some patterns from it and if we can  

527
01:09:24,880 --> 01:09:29,800
learn the patterns from it we can understand its 
meaning if we can understand its meaning we might  

528
01:09:29,800 --> 01:09:36,439
be able to generate it as well and so therefore 
the generative AI Revolution is here well what  

529
01:09:36,439 --> 01:09:41,879
else can we generate what else can we learn well 
one of the things that we would love to learn we  

530
01:09:41,880 --> 01:09:49,359
would love to learn is we would love to learn 
climate we would love to learn extreme weather  

531
01:09:49,359 --> 01:09:59,680
we would love to learn uh what how we can predict 
future weather at Regional scales at sufficiently  

532
01:09:59,680 --> 01:10:06,280
high resolution such that we can keep people out 
of Harm's Way before harm comes extreme weather  

533
01:10:06,280 --> 01:10:13,440
cost the world $150 billion surely more than that 
and it's not evenly distributed $150 billion is  

534
01:10:13,440 --> 01:10:18,040
concentrated in some parts of the world and of 
course to some people of the world we need to  

535
01:10:18,040 --> 01:10:23,880
adapt and we need to know what's coming and so 
we are creating Earth too a digital twin of the  

536
01:10:23,880 --> 01:10:31,600
Earth for predicting weather we and we've made an 
extraordinary invention called Civ the ability to  

537
01:10:31,600 --> 01:10:40,200
use generative AI to predict weather at extremely 
high resolution let's take a look as the earth's  

538
01:10:40,200 --> 01:10:45,360
climate changes AI powered weather forecasting 
is allowing us to more accurately predict and  

539
01:10:45,360 --> 01:10:51,000
track severe storms like super typhoon chanthu 
which caused widespread damage in Taiwan and  

540
01:10:51,000 --> 01:10:57,640
the surrounding region in 2021 current AI forecast 
models can accurately predict the track of storms  

541
01:10:57,640 --> 01:11:04,520
but they are limited to 25 km resolution which 
can miss important details Invidia cordi is a  

542
01:11:04,520 --> 01:11:10,120
revolutionary new generative AI model trained on 
high resolution radar assimilated Warf weather  

543
01:11:10,120 --> 01:11:17,600
forecasts and air 5 reanalysis data using cordi 
extreme events like chanthu can be super resolved  

544
01:11:17,600 --> 01:11:24,440
from 25 km to 2 km resolution with 1,000 times 
the speed and 3,000 times the Energy Efficiency  

545
01:11:24,440 --> 01:11:30,040
of conventional weather models by combining the 
speed and accuracy of nvidia's weather forecasting  

546
01:11:30,040 --> 01:11:36,200
model forecast net and generative AI models like 
cordi we can explore hundreds or even thousands  

547
01:11:36,200 --> 01:11:41,760
of kilometer scale Regional weather forecasts 
to provide a clear picture of the best worst  

548
01:11:41,760 --> 01:11:47,400
and most likely impacts of a storm this wealth 
of information can help minimize loss of life  

549
01:11:47,400 --> 01:11:53,480
and property damage today cordi is optimized 
for Taiwan but soon generative super sampling  

550
01:11:53,480 --> 01:11:58,400
will be available as part of the in viia Earth 
2 inference service for many regions across the

551
01:11:58,400 --> 01:12:04,500
[Music]

552
01:12:04,500 --> 01:12:15,240
globe the weather company has the trust a source 
of global weather predictions we are working  

553
01:12:15,240 --> 01:12:21,480
together to accelerate their weather simulation 
first principled base of simulation however  

554
01:12:21,480 --> 01:12:27,240
they're also going to integrate Earth to cordi so 
that they could help businesses and countries do  

555
01:12:27,240 --> 01:12:32,600
Regional high resolution weather prediction and 
so if you have some weather prediction you'd like  

556
01:12:32,600 --> 01:12:38,200
to know like to do uh reach out to the weather 
company really exciting really exciting work  

557
01:12:38,200 --> 01:12:43,640
Nvidia Healthcare something we started 15 years 
ago we're super super excited about this this is  

558
01:12:43,640 --> 01:12:48,720
an area where we're very very proud whether 
it's Medical Imaging or genene sequencing or  

559
01:12:48,720 --> 01:12:56,240
computational chemistry it is very likely that 
Nvidia is the computation behind it we've done  

560
01:12:56,240 --> 01:13:02,640
so much work in this area today we're announcing 
that we're going to do something really really  

561
01:13:02,640 --> 01:13:12,840
cool imagine all of these AI models that are being 
used to generate images and audio but instead of  

562
01:13:12,840 --> 01:13:18,560
images and audio because it understood images 
and audio all the digitization that we've done  

563
01:13:18,560 --> 01:13:26,600
for genes and proteins and amino acids that 
digitalization capability is now now passed  

564
01:13:26,600 --> 01:13:32,040
through machine learning so that we understand 
the language of Life the ability to understand  

565
01:13:32,040 --> 01:13:37,960
the language of Life of course we saw the 
first evidence of it with alphafold this  

566
01:13:37,960 --> 01:13:43,440
is really quite an extraordinary thing after 
Decades of painstaking work the world had only  

567
01:13:43,440 --> 01:13:52,720
digitized and reconstructed using cor electron 
microscopy or Crystal XR x-ray crystallography  

568
01:13:52,720 --> 01:13:58,320
um these different techniques painstaking 
reconstructed the protein 200,000 of them  

569
01:13:58,320 --> 01:14:06,000
in just what is it less than a year or so 
Alpha fold has reconstructed 200 million  

570
01:14:06,000 --> 01:14:11,760
proteins basically every protein every of every 
living thing that's ever been sequenced this is  

571
01:14:11,760 --> 01:14:18,320
completely revolutionary well those models are 
incredibly hard to use um for incredibly hard  

572
01:14:18,320 --> 01:14:21,800
for people to build and so what we're going to 
do is we're going to build them we're going to  

573
01:14:21,800 --> 01:14:26,760
build them for uh the the researchers around 
the world and it won't be the only one there'll  

574
01:14:26,760 --> 01:14:30,440
be many other models that we create and so 
let me show you what we're going to do with

575
01:14:30,440 --> 01:14:40,560
it virtual screening for new medicines 
is a computationally intractable problem  

576
01:14:40,560 --> 01:14:45,640
existing techniques can only scan billions 
of compounds and require days on thousands of  

577
01:14:45,640 --> 01:14:52,360
standard compute nodes to identify new drug 
candidates Nvidia biion Nemo Nims enable a  

578
01:14:52,360 --> 01:14:57,200
new generative screening Paradigm using Nims 
for protein structure prediction with Alpha  

579
01:14:57,200 --> 01:15:04,000
fold molecule generation with MIM and docking 
with diff dock we can now generate and Screen  

580
01:15:04,000 --> 01:15:09,840
candidate molecules in a matter of minutes MIM 
can connect to custom applications to steer the  

581
01:15:09,840 --> 01:15:15,960
generative process iteratively optimizing for 
desired properties these applications can be  

582
01:15:15,960 --> 01:15:22,520
defined with biion Nemo microservices or built 
from scratch here a physics based simulation  

583
01:15:22,520 --> 01:15:27,920
optimizes for a molecule's ability to bind to 
a Target protein while optimizing for other  

584
01:15:27,920 --> 01:15:34,240
favorable molecular properties in parallel MIM 
generates high quality drug-like molecules that  

585
01:15:34,240 --> 01:15:39,040
bind to the Target and are synthesizable 
translating to a higher probability of  

586
01:15:39,040 --> 01:15:45,600
developing successful medicines faster biion Nemo 
is enabling a new paradigm in drug Discovery with  

587
01:15:45,600 --> 01:15:50,880
Nims providing OnDemand microservices 
that can be combined to build powerful  

588
01:15:50,880 --> 01:15:56,840
drug Discovery workflows like denovo protein 
design or ided molecule generation for virtual  

589
01:15:56,840 --> 01:16:03,200
screening bio Nims are helping researchers 
and developers reinvent computational drug

590
01:16:03,200 --> 01:16:17,360
design Nvidia M MIM MIM cord diff there's a whole 
bunch of other models whole bunch of other models  

591
01:16:17,360 --> 01:16:24,400
computer vision models robotics models and 
even of course some really really terrific  

592
01:16:24,400 --> 01:16:31,760
open source language models these models are 
groundbreaking however it's hard for companies  

593
01:16:31,760 --> 01:16:36,080
to use how would you use it how would you bring 
it into your company and integrate it into your  

594
01:16:36,080 --> 01:16:42,560
workflow how would you package it up and run it 
remember earlier I just said that inference is  

595
01:16:42,560 --> 01:16:48,480
an extraordinary computation problem how would 
you do the optimization for each and every one  

596
01:16:48,480 --> 01:16:54,280
of these models and put together the Computing 
stack necessary to run that supercomputer so that  

597
01:16:54,280 --> 01:17:01,880
you can run the models in your company and so we 
have a great idea we're going to invent a new way  

598
01:17:01,880 --> 01:17:11,880
invent a new way for you to receive and operate 
software this software comes basically in a  

599
01:17:11,880 --> 01:17:20,520
digital box we call it a container and we call it 
the Nvidia inference micr service a Nim and let me  

600
01:17:20,520 --> 01:17:28,400
explain to you what it is a Nim it's a pre-trained 
model so it's pretty clever and it is packaged  

601
01:17:28,400 --> 01:17:34,720
and optimized to run across nvidia's install 
base which is very very large what's inside  

602
01:17:34,720 --> 01:17:41,240
it is incredible you have all these pre-trained 
state-ofthe-art open source models they could be  

603
01:17:41,240 --> 01:17:46,520
open source they could be from one of our partners 
it could be created by us like Nvidia mull it is  

604
01:17:46,520 --> 01:17:53,440
packaged up with all of its dependencies so Cuda 
the right version CNN the right version tensor RT  

605
01:17:53,440 --> 01:18:00,840
llm Distributing across the multiple gpus Tred and 
inference server all completely packaged together  

606
01:18:00,840 --> 01:18:06,840
it's optimized depending on whether you have a 
single GPU multi- GPU or multi node of gpus it's  

607
01:18:06,840 --> 01:18:13,240
optimized for that and it's connected up with apis 
that are simple to use now this think about what  

608
01:18:13,240 --> 01:18:21,680
an AI API is an AI API is an interface that you 
just talk to and so this is a piece of software in  

609
01:18:21,680 --> 01:18:29,360
the future that has a really simple API and that 
API called human and these packages incredible  

610
01:18:29,360 --> 01:18:36,760
bodies of software will be optimized and packaged 
and we'll put it on a website and you can download  

611
01:18:36,760 --> 01:18:41,760
it you could take it with you you could run 
it in any Cloud you can run it in your own  

612
01:18:41,760 --> 01:18:47,280
data center you can run in workstations if it fit 
and all you have to do is come to ai. nvidia.com  

613
01:18:47,280 --> 01:18:54,720
we call it Nvidia inference microservice but 
inside the company we all call it Nims okay

614
01:19:02,080 --> 01:19:07,760
just imagine you know one of some someday there 
there's going to be one of these chat Bots and  

615
01:19:07,760 --> 01:19:13,480
these chat Bots is going to just be in a Nim and 
you you'll uh you'll assemble a whole bunch of  

616
01:19:13,480 --> 01:19:18,600
chat Bots and that's the way software is going 
to be be built someday how do we build software  

617
01:19:18,600 --> 01:19:23,920
in the future it is unlikely that you'll write 
it from scratch or write a whole bunch of python  

618
01:19:23,920 --> 01:19:30,640
code or anything like that it is very likely that 
you assemble a team of AIS there's probably going  

619
01:19:30,640 --> 01:19:36,520
to be a super AI that you use that takes the 
mission that you give it and breaks it down  

620
01:19:36,520 --> 01:19:43,760
into an execution plan some of that execution plan 
could be handed off to another Nim that Nim would  

621
01:19:43,760 --> 01:19:52,240
maybe uh understand sap the language of sap is 
abap it might understand service now and it go  

622
01:19:52,240 --> 01:19:57,960
retrieve some information from their platforms 
it might then hand that result to another Nim  

623
01:19:57,960 --> 01:20:03,400
who that goes off and does some calculation 
on it maybe it's an optimization software a  

624
01:20:03,400 --> 01:20:11,120
combinatorial optimization algorithm maybe it's 
uh you know some just some basic calculator maybe  

625
01:20:11,120 --> 01:20:18,760
it's pandas to do some numerical analysis on it 
and then it comes back with its answer and it  

626
01:20:18,760 --> 01:20:24,160
gets combined with everybody else's and it because 
it's been presented with this is what the right  

627
01:20:24,160 --> 01:20:29,360
answer should look like it knows what answer what 
an what right answers to produce and it presents  

628
01:20:29,360 --> 01:20:34,680
it to you we can get a report every single day at 
you know top of the hour uh that has something to  

629
01:20:34,680 --> 01:20:40,080
do with a bill plan or some forecast or uh some 
customer alert or some bugs database or whatever  

630
01:20:40,080 --> 01:20:45,920
it happens to be and we could assemble it using 
all these Nims and because these Nims have been  

631
01:20:45,920 --> 01:20:51,720
packaged up and ready to work on your systems so 
long as you have video gpus in your data center in  

632
01:20:51,720 --> 01:20:59,920
the cloud this this Nims will work together as a 
team and do amazing things and so we decided this  

633
01:20:59,920 --> 01:21:05,600
is such a great idea we're going to go do that and 
so Nvidia has Nims running all over the company we  

634
01:21:05,600 --> 01:21:10,800
have chatbots being created all over the place 
and one of the mo most important chatbots of  

635
01:21:10,800 --> 01:21:17,000
course is a chip designer chatbot you might not 
be surprised we care a lot about building chips  

636
01:21:17,000 --> 01:21:25,640
and so we want to build chatbots AI co-pilots that 
are co-designers with our engineers and so this  

637
01:21:25,640 --> 01:21:32,960
is the way we did it so we got ourselves a llama 
llama 2 this is a 70b and it's you know packaged  

638
01:21:32,960 --> 01:21:42,920
up in a NM and we asked it you know uh what is a 
CTL Well turns out CTL is an internal uh program  

639
01:21:42,920 --> 01:21:47,960
and it has a internal proprietary language but 
it thought the CTL was a combinatorial timing  

640
01:21:47,960 --> 01:21:54,320
logic and so it describes you know conventional 
knowledge of CTL but that's not very useful to us  

641
01:21:54,320 --> 01:22:00,320
and so we gave it a whole bunch of new examples 
you know this is no different than employee  

642
01:22:00,320 --> 01:22:06,840
onboarding an employee uh we say you know thanks 
for that answer it's completely wrong um and and  

643
01:22:06,840 --> 01:22:12,880
uh and then we present to them uh this is what 
a CTL is okay and so this is what a CTL is at  

644
01:22:12,880 --> 01:22:19,480
Nvidia and the CTL as you can see you know CTL 
stands for compute Trace Library which makes  

645
01:22:19,480 --> 01:22:25,400
sense you know we were tracing compute Cycles 
all the time and it wrote the program isn't that

646
01:22:25,400 --> 01:22:36,400
amazing and so the productivity of our chip 
designers can go up this is what you can do with  

647
01:22:36,400 --> 01:22:41,440
a Nim first thing you can do with is customize 
it we have a service called Nemo microservice  

648
01:22:41,440 --> 01:22:46,360
that helps you curate the data preparing the 
data so that you could teach this on board  

649
01:22:46,360 --> 01:22:53,120
this AI you fine-tune them and then you guardrail 
it you can even evaluate the answer evaluate its  

650
01:22:53,120 --> 01:23:00,080
performance against um other other examples and 
so that's called the Nemo micr service now the  

651
01:23:00,080 --> 01:23:03,840
thing that's that's emerging here is this there 
are three elements three pillars of what we're  

652
01:23:03,840 --> 01:23:10,240
doing the first pillar is of course inventing 
the technology for um uh AI models and running  

653
01:23:10,240 --> 01:23:16,760
AI models and packaging it up for you the second 
is to create tools to help you modify it first  

654
01:23:16,760 --> 01:23:22,120
is having the AI technology second is to help you 
modify it and third is infrastructure for you to  

655
01:23:22,120 --> 01:23:27,320
fine-tune it and if you like deploy it you could 
deploy it on our infrastructure called dgx cloud  

656
01:23:27,320 --> 01:23:32,840
or you can employ deploy it on Prem you can deploy 
it anywhere you like once you develop it it's  

657
01:23:32,840 --> 01:23:41,720
yours to take anywhere and so we are effectively 
an AI Foundry we will do for you and the industry  

658
01:23:41,720 --> 01:23:48,120
on AI what tsmc does for us building chips and 
so we go to it with our go to tsmc with our big  

659
01:23:48,120 --> 01:23:54,000
Ideas they manufacture and we take it with us and 
so exactly the same thing here AI Foundry and the  

660
01:23:54,000 --> 01:24:00,560
three pillar ERS are the NIMS Nemo microservice 
and dgx Cloud the other thing that you could teach  

661
01:24:00,560 --> 01:24:07,000
the Nim to do is to understand your proprietary 
information remember inside our company the vast  

662
01:24:07,000 --> 01:24:11,680
majority of our data is not in the cloud it's 
inside our company it's been sitting there you  

663
01:24:11,680 --> 01:24:18,480
know being used all the time and and gosh it's 
it's basically invidious intelligence we would  

664
01:24:18,480 --> 01:24:24,840
like to take that data learn its meaning like we 
learned the meaning of almost anything else that  

665
01:24:24,840 --> 01:24:31,520
we just talked about learn its meaning and then 
reindex that knowledge into a new type of database  

666
01:24:31,520 --> 01:24:37,160
called a vector database and so you essentially 
take structured data or unstructured data you  

667
01:24:37,160 --> 01:24:44,800
learn its meaning you encode its meaning so now 
this becomes an AI database and that AI database  

668
01:24:44,800 --> 01:24:48,920
in the future once you create it you can talk to 
it and so let me give you an example of what you  

669
01:24:48,920 --> 01:24:53,920
could do so suppose you create you get you got a 
whole bunch of multi modality data and one good  

670
01:24:53,920 --> 01:25:00,640
example of that is PDF so you take the PDF you 
take all of your PDFs all the all your favorite  

671
01:25:00,640 --> 01:25:06,920
you know the stuff that that is proprietary to 
you critical to your company you can encode it  

672
01:25:06,920 --> 01:25:13,080
just as we encoded pixels of a cat and it becomes 
the word cat we can encode all of your PDF and it  

673
01:25:13,080 --> 01:25:19,120
turns into vectors that are now stored inside 
your vector database it becomes the proprietary  

674
01:25:19,120 --> 01:25:23,400
information of your company and once you have 
that proprietary information you can chat to  

675
01:25:23,400 --> 01:25:30,200
it it's an it's a smart database and so you just 
ch chat with data and how how much more enjoyable  

676
01:25:30,200 --> 01:25:37,560
is that you know we for for our software team 
you know they just chat with the bugs database  

677
01:25:37,560 --> 01:25:43,000
you know how many bugs was there last night um 
are we making any progress and then after you're  

678
01:25:43,000 --> 01:25:50,920
done talking to this uh bugs database you need 
therapy and so so we have another chatbot for

679
01:25:50,920 --> 01:25:55,960
you you can do

680
01:25:55,960 --> 01:26:10,920
it okay so we call this Nemo Retriever and the 
reason for that is because ultimately it's job  

681
01:26:10,920 --> 01:26:15,120
is to go retrieve information as quickly as 
possible and you just talk to it hey retrieve  

682
01:26:15,120 --> 01:26:21,280
me this information it goes if brings it back to 
you and do you mean this you go yeah perfect okay  

683
01:26:21,280 --> 01:26:25,640
and so we call it the Nemo retriever well the 
Nemo service helps you create all these things  

684
01:26:25,640 --> 01:26:31,240
and we have all all these different Nims we 
even have Nims of digital humans I'm Rachel  

685
01:26:31,240 --> 01:26:39,280
your AI care manager okay so so it's a really 
short clip but there were so many videos to  

686
01:26:39,280 --> 01:26:44,080
show you I guess so many other demos to show 
you and so I I had to cut this one short but  

687
01:26:44,080 --> 01:26:51,360
this is Diana she is a digital human Nim 
and and uh you just talked to her and she's  

688
01:26:51,360 --> 01:26:56,360
connected in this case to Hippocratic ai's large 
language model for healthcare and it's truly

689
01:26:56,360 --> 01:27:05,400
amazing she is just super smart about Healthcare 
things you know and so after you're done after my  

690
01:27:05,400 --> 01:27:11,160
my Dwight my VP of software engineering talks to 
the chatbot for bugs database then you come over  

691
01:27:11,160 --> 01:27:18,160
here and talk to Diane and and so so uh Diane 
is is um completely animated with AI and she's  

692
01:27:18,160 --> 01:27:24,120
a digital human uh there's so many companies that 
would like to build they're sitting on gold mines  

693
01:27:25,200 --> 01:27:30,800
the the Enterprise IT industry is sitting on a 
gold mine it's a gold mine because they have so  

694
01:27:30,800 --> 01:27:36,200
much understanding of of uh the way work is 
done they have all these amazing tools that  

695
01:27:36,200 --> 01:27:40,880
have been created over the years and they're 
sitting on a lot of data if they could take  

696
01:27:40,880 --> 01:27:47,320
that gold mine and turn them into co-pilots 
these co-pilots could help us do things and  

697
01:27:47,320 --> 01:27:53,680
so just about every it franchise it platform in 
the world that has valuable tools that people use  

698
01:27:53,680 --> 01:27:58,160
is sitting on a gold mine for co-pilots and 
they would like to build their own co-pilots  

699
01:27:58,160 --> 01:28:03,320
and their own chatbots and so we're announcing 
that Nvidia AI foundary is working with some  

700
01:28:03,320 --> 01:28:09,000
of the world's great companies sap generates 
87% of the world's Global Commerce basically  

701
01:28:09,000 --> 01:28:16,040
the world runs on sap we run on sap Nvidia and 
sap are building sap Jewel co-pilots uh using  

702
01:28:16,040 --> 01:28:22,880
Nvidia Nemo and dgx cloud service now they run 
80 85% of the world's Fortune 500 companies run  

703
01:28:22,880 --> 01:28:29,520
their people and customer service operations on 
service now and they're using Nvidia AI Foundry  

704
01:28:29,520 --> 01:28:37,720
to build service now uh assist virtual assistance 
cohesity backs up the world's data they're sitting  

705
01:28:37,720 --> 01:28:44,160
on a gold mine of data hundreds of exobytes of 
data over 10,000 companies Nvidia AI Foundry is  

706
01:28:44,160 --> 01:28:52,000
working with them helping them build their Gaia 
generative AI agent snowflake is a company that  

707
01:28:52,000 --> 01:28:58,800
stores the world's uh digital Warehouse in 
the cloud and serves over 3 billion queries  

708
01:28:58,800 --> 01:29:07,360
a day for 10,000 Enterprise customers snowflake is 
working with Nvidia AI Foundry to build co-pilots  

709
01:29:07,360 --> 01:29:15,640
with Nvidia Nemo and Nims net apppp nearly half 
of the files in the world are stored on Prem on  

710
01:29:15,640 --> 01:29:21,720
net apppp Nvidia AI Foundry is helping them uh 
build chat Bots and co-pilots like those Vector  

711
01:29:21,720 --> 01:29:28,800
databases and retrievers with Nvidia neemo and 
Nims and we have a great partnership with Dell  

712
01:29:28,800 --> 01:29:34,800
everybody who everybody who is building these 
chat Bots and generative AI when you're ready  

713
01:29:34,800 --> 01:29:42,240
to run it you're going to need an AI Factory and 
nobody is better at Building end-to-end Systems  

714
01:29:42,240 --> 01:29:48,600
of very large scale for the Enterprise than 
Dell and so anybody any company every company  

715
01:29:48,600 --> 01:29:54,040
will need to build AI factories and it turns out 
that Michael is here he's happy to take your order

716
01:29:58,040 --> 01:29:59,760
ladies and gentlemen Michael

717
01:29:59,760 --> 01:30:10,400
del okay let's talk about the next wave of 
Robotics the next wave of AI robotics physical  

718
01:30:10,400 --> 01:30:19,240
AI so far all of the AI that we've talked about is 
one computer data comes into one computer lots of  

719
01:30:19,240 --> 01:30:27,920
the world's if you will experience in digital 
text form the AI imitates Us by reading a lot  

720
01:30:27,920 --> 01:30:33,320
of the language to predict the next words it's 
imitating You by studying all of the patterns  

721
01:30:33,320 --> 01:30:37,920
and all the other previous examples of course it 
has to understand context and so on so forth but  

722
01:30:37,920 --> 01:30:42,880
once it understands the context it's essentially 
imitating you we take all of the data we put it  

723
01:30:42,880 --> 01:30:48,960
into a system like dgx we compress it into a 
large language model trillions and trillions of  

724
01:30:48,960 --> 01:30:53,400
parameters become billions and billion trillions 
of tokens becomes billions of parameters these  

725
01:30:53,400 --> 01:30:59,320
billions of parameters becomes your AI well 
in order for us to go to the next wave of AI  

726
01:30:59,320 --> 01:31:05,760
where the AI understands the physical world we're 
going to need three computers the first computer  

727
01:31:05,760 --> 01:31:10,960
is still the same computer it's that AI computer 
that now is going to be watching video and maybe  

728
01:31:10,960 --> 01:31:17,080
it's doing synthetic data generation and maybe 
there's a lot of human examples just as we have  

729
01:31:17,080 --> 01:31:23,120
human examples in text form we're going to have 
human examples in articulation form and the AIS  

730
01:31:23,120 --> 01:31:32,400
will watch us understand what is happening and try 
to adapt it for themselves into the context and  

731
01:31:32,400 --> 01:31:38,040
because it can generalize with these Foundation 
models maybe these robots can also perform in  

732
01:31:38,040 --> 01:31:44,720
the physical world fairly generally so I just 
described in very simple terms essentially what  

733
01:31:44,720 --> 01:31:49,520
just happened in large language models except 
the chat GPT moment for robotics may be right  

734
01:31:49,520 --> 01:31:54,720
around the corner and so we've been building 
the end to-end systems for robotics for some  

735
01:31:54,720 --> 01:32:01,560
time I'm super super proud of the work we have 
the AI system dgx we have the lower system which  

736
01:32:01,560 --> 01:32:06,720
is called agx for autonomous systems the world's 
first robotics processor when we first built this  

737
01:32:06,720 --> 01:32:11,560
thing people are what are you guys building 
it's a s so it's one chip it's designed to be  

738
01:32:11,560 --> 01:32:18,480
very low power but it's designed for high-speed 
sensor processing and Ai and so if you want to  

739
01:32:18,480 --> 01:32:24,680
run Transformers in a car or you want to run 
Transformers in a in a you know anything um  

740
01:32:24,680 --> 01:32:30,920
that moves uh we have the perfect computer for you 
it's called the Jetson and so the dgx on top for  

741
01:32:30,920 --> 01:32:36,080
training the AI the Jetson is the autonomous 
processor and in the middle we need another  

742
01:32:36,080 --> 01:32:44,040
computer whereas large language models have the 
benefit of you providing your examples and then  

743
01:32:44,040 --> 01:32:51,080
doing reinforcement learning human feedback what 
is the reinforcement learning human feedback of a  

744
01:32:51,080 --> 01:32:57,840
robot well it's reinforcement learning physical 
feedback that's how you align the robot that's  

745
01:32:57,840 --> 01:33:02,560
how you that's how the robot knows that as 
it's learning these articulation capabilities  

746
01:33:02,560 --> 01:33:09,240
and manipulation capabilities it's going to adapt 
properly into the laws of physics and so we need  

747
01:33:09,240 --> 01:33:16,000
a simulation engine that represents the world 
digitally for the robot so that the robot has  

748
01:33:16,000 --> 01:33:24,760
a gym to go learn how to be a robot we call that 
virtual world Omniverse and the computer that runs  

749
01:33:24,760 --> 01:33:32,560
Omniverse is called ovx and ovx the computer 
itself is hosted in the Azure Cloud okay and  

750
01:33:32,560 --> 01:33:37,240
so basically we built these three things these 
three systems on top of it we have algorithms  

751
01:33:37,240 --> 01:33:44,720
for every single one now I'm going to show you one 
super example of how Ai and Omniverse are going to  

752
01:33:44,720 --> 01:33:49,640
work together the example I'm going to show you 
is kind of insane but it's going to be very very  

753
01:33:49,640 --> 01:33:56,560
close to tomorrow it's a robotics building this 
robotics building is called a warehouse inside the  

754
01:33:56,560 --> 01:34:01,200
robotics building are going to be some autonomous 
systems some of the autonomous systems are going  

755
01:34:01,200 --> 01:34:06,600
to be called humans and some of the autonomous 
systems are going to be called forklifts and  

756
01:34:06,600 --> 01:34:12,040
these autonomous systems are going to interact 
with each other of course autonomously and it's  

757
01:34:12,040 --> 01:34:17,360
going to be overlooked upon by this Warehouse to 
keep everybody out of Harm's Way the warehouse  

758
01:34:17,360 --> 01:34:22,920
is essentially an air traffic controller and 
whenever it sees something happening it will  

759
01:34:22,920 --> 01:34:28,400
redirect traffic traffic and give New Way points 
just new way points to the robots and the people  

760
01:34:28,400 --> 01:34:35,320
and they'll know exactly what to do this warehouse 
this building you can also talk to of course you  

761
01:34:35,320 --> 01:34:42,480
could talk to it hey you know sap Center how are 
you feeling today for example and so you could  

762
01:34:42,480 --> 01:34:47,880
ask the same the warehouse the same questions 
basically the system I just described will have  

763
01:34:47,880 --> 01:34:55,720
Omniverse Cloud that's hosting the virtual 
simulation and AI running on djx cloud and  

764
01:34:55,720 --> 01:35:02,720
all of this is running in real time let's take 
a look the future of heavy industri starts as a  

765
01:35:02,720 --> 01:35:09,520
digital twin the AI agents helping robots workers 
and infrastructure navigate unpredictable events  

766
01:35:09,520 --> 01:35:15,080
in complex industrial spaces will be built 
and evaluated first in sophisticated digital  

767
01:35:15,080 --> 01:35:23,280
twins this Omniverse digital twin of a 100,000 ft 
Warehouse is operating as a simulation environment  

768
01:35:23,280 --> 01:35:30,080
that integrates digital workers amrs running the 
Nvidia Isaac receptor stack centralized activity  

769
01:35:30,080 --> 01:35:36,360
maps of the entire Warehouse from 100 simulated 
ceiling mount cameras using Nvidia metropolis  

770
01:35:36,360 --> 01:35:43,520
and AMR route planning with Nvidia Koop software 
in Loop testing of AI agents in this physically  

771
01:35:43,520 --> 01:35:49,680
accurate simulated environment enables us to 
evaluate and refine how the system adapts to real  

772
01:35:49,680 --> 01:35:56,840
world unpredictability here an incident occurs 
along this amr's planned route blocking its path  

773
01:35:56,840 --> 01:36:03,640
as it moves to pick up a pallet Nvidia Metropolis 
updates and sends a realtime occupancy map to kopt  

774
01:36:03,640 --> 01:36:09,480
where a new optimal route is calculated the AMR 
is enabled to see around corners and improve its  

775
01:36:09,480 --> 01:36:15,760
Mission efficiency with generative AI powered 
Metropolis Vision Foundation models operators  

776
01:36:15,760 --> 01:36:22,040
can even ask questions using natural language the 
visual model understands nuanced activity and can  

777
01:36:22,040 --> 01:36:27,880
offer immediate insights to improve operations 
all of the sensor data is created in simulation  

778
01:36:27,880 --> 01:36:34,760
and passed to the real-time AI running as Nvidia 
inference microservices or Nims and when the AI is  

779
01:36:34,760 --> 01:36:40,960
ready to be deployed in the physical twin the real 
Warehouse we connect metropolis and Isaac Nims  

780
01:36:40,960 --> 01:36:46,880
to real sensors with the ability for continuous 
Improvement of both the digital twin and the AI

781
01:36:46,880 --> 01:37:02,200
models isn't that incredible and so remember 
remember a future facility Warehouse Factory  

782
01:37:02,200 --> 01:37:07,760
building will be software defined and so the 
software is running how else would you test  

783
01:37:07,760 --> 01:37:13,320
the software so you you you test the software to 
building the warehouse the optimization system in  

784
01:37:13,320 --> 01:37:17,720
the digital twin what about all the robots all of 
those robots you are seeing just now they're all  

785
01:37:17,720 --> 01:37:23,640
running their own autonomous robotic stack and so 
the way you integrate software in the future cicd  

786
01:37:23,640 --> 01:37:30,680
in the future for robotic systems is with digital 
twins we've made Omniverse a lot easier to access  

787
01:37:30,680 --> 01:37:37,000
we're going to create basically Omniverse Cloud 
apis four simple API and a channel and you can  

788
01:37:37,000 --> 01:37:43,320
connect your application to it so this is this 
is going to be as wonderfully beautifully simple  

789
01:37:43,320 --> 01:37:48,920
in the future that Omniverse is going to be and 
with these apis you're going to have these magical  

790
01:37:48,920 --> 01:37:58,080
digital twin capability we also have turned om ver 
into an AI and integrated it with the ability to  

791
01:37:58,080 --> 01:38:04,000
chat USD the the language of our language is 
you know human and Omniverse is language as  

792
01:38:04,000 --> 01:38:10,440
it turns out is universal scene description and 
so that language is rather complex and so we've  

793
01:38:10,440 --> 01:38:15,200
taught our Omniverse uh that language and so 
you can speak to it in English and it would  

794
01:38:15,200 --> 01:38:20,720
directly generate USD and it would talk back 
in USD but Converse back to you in English you  

795
01:38:20,720 --> 01:38:26,600
could also look for information in this world 
semantically instead of the world being encoded  

796
01:38:26,600 --> 01:38:31,640
semantically in in language now it's encoded 
semantically in scenes and so you could ask  

797
01:38:31,640 --> 01:38:37,040
it of of uh certain objects or certain conditions 
and certain scenarios and it can go and find that  

798
01:38:37,040 --> 01:38:41,880
scenario for you it also can collaborate with 
you in generation you could design some things  

799
01:38:41,880 --> 01:38:47,440
in 3D it could simulate some things in 3D or 
you could use AI to generate something in 3D  

800
01:38:47,440 --> 01:38:52,520
let's take a look at how this is all going to work 
we have a great partnership with Seamans Seamans  

801
01:38:52,520 --> 01:38:59,280
is the world's largest industrial engineering 
and operations platform you've seen now so many  

802
01:38:59,280 --> 01:39:05,120
different companies in the industrial space heavy 
Industries is one of the greatest final frontiers  

803
01:39:05,120 --> 01:39:11,960
of it and we finally now have the Necessary 
Technology to go and make a real impact seens  

804
01:39:11,960 --> 01:39:17,040
is building the industrial metaverse and today 
we're announcing that Seamans is connecting their  

805
01:39:17,040 --> 01:39:25,560
Crown Jewel accelerator to Nvidia Omniverse let's 
take a look seens technology is transformed every  

806
01:39:25,560 --> 01:39:31,080
day for everyone team Center acts our leading 
product life cycle management software from the  

807
01:39:31,080 --> 01:39:37,560
sems accelerator platform is used every day by 
our customers to develop and deliver products  

808
01:39:37,560 --> 01:39:44,040
at scale now we are bringing the real and the 
digital worlds even Closer by integrating Nvidia  

809
01:39:44,040 --> 01:39:51,840
Ai and Omniverse Technologies into team Center X 
Omniverse apis enable data interoperability and  

810
01:39:51,840 --> 01:39:59,560
physics-based rendering to Industrial scale design 
and Manufacturing projects our customers HD market  

811
01:39:59,560 --> 01:40:05,720
leader in sustainable ship manufacturing builds 
ammonia and hydrogen power chips often comprising  

812
01:40:05,720 --> 01:40:14,000
over 7 million discrete Parts with Omniverse apis 
team Center X lets companies like HD yundai unify  

813
01:40:14,000 --> 01:40:20,320
and visualize these massive engineering data 
sets interactively and integrate generative AI  

814
01:40:20,320 --> 01:40:28,320
to generate 3D objects or HDR I backgrounds 
to see their projects in context the result  

815
01:40:28,320 --> 01:40:35,120
an ultra inuitive photoal physics-based digital 
twin that eliminates waste and errors delivering  

816
01:40:35,120 --> 01:40:41,920
huge savings in cost and time and we are building 
this for collaboration whether across more semens  

817
01:40:41,920 --> 01:40:49,760
accelerator tools like seens anex or Star CCM 
Plus or across teams working on their favorite  

818
01:40:49,760 --> 01:40:56,560
devices in the same scene together in this is 
just the beginning working with Nvidia we will  

819
01:40:56,560 --> 01:41:03,960
bring accelerated Computing generative Ai and 
Omniverse integration across the Sean accelerator

820
01:41:03,960 --> 01:41:17,800
portfolio the pro the the professional 
the professional voice actor happens to  

821
01:41:17,800 --> 01:41:23,240
be a good friend of mine Roland Bush 
who happens to be the CEO of seens

822
01:41:29,800 --> 01:41:38,080
once you get Omniverse connected into your 
workflow your ecosystem from the beginning  

823
01:41:38,080 --> 01:41:46,840
of your design to engineering to manufacturing 
planning all the way to digital twin operations  

824
01:41:46,840 --> 01:41:52,560
once you connect everything together it's insane 
how much productivity you can get and it's just  

825
01:41:52,560 --> 01:41:57,800
really really wonderful all of a sudden everybody 
is operating on the same ground truth you don't  

826
01:41:57,800 --> 01:42:02,920
have to exchange data and convert data make 
mistakes everybody is working on the same  

827
01:42:02,920 --> 01:42:07,920
ground truth from the design Department to the 
art Department the architecture Department all  

828
01:42:07,920 --> 01:42:13,840
the way to the engineering and even the marketing 
department let's take a look at how Nissan has  

829
01:42:13,840 --> 01:42:19,200
integrated Omniverse into their workflow 
and it's all because it's connected by all  

830
01:42:19,200 --> 01:42:23,160
these wonderful tools and these developers 
that we're working with take a look unbel

831
01:42:23,160 --> 01:42:23,160
[Music]

832
01:42:52,160 --> 01:42:53,160
[Music]

833
01:42:53,160 --> 01:43:23,120
for

834
01:43:23,120 --> 01:43:23,120
[Music]

835
01:43:31,080 --> 01:43:53,040
for

836
01:44:01,920 --> 01:44:06,760
that was not an animation that was Omniverse today  

837
01:44:06,760 --> 01:44:13,480
we're announcing that Omniverse 
Cloud streams to The Vision Pro

838
01:44:13,480 --> 01:44:30,000
and it is very very strange that you walk around 
virtual doors when I was getting out of that car  

839
01:44:30,000 --> 01:44:37,520
and everybody does it it is really really quite 
amazing Vision Pro connected to Omniverse portals  

840
01:44:37,520 --> 01:44:42,720
you into Omniverse and because all of these CAD 
tools and all these different design tools are  

841
01:44:42,720 --> 01:44:48,600
now integrated and connected to Omniverse you can 
have this type of workflow really incredible let's  

842
01:44:48,600 --> 01:44:53,920
talk about robotics everything that moves will be 
robotic there's no question about that it's safer  

843
01:44:53,920 --> 01:45:00,560
it's more convenient and one of the largest 
Industries is going to be Automotive we build  

844
01:45:00,560 --> 01:45:05,440
the robotic stack from top to bottom as I was 
mentioned from the computer system but in the case  

845
01:45:05,440 --> 01:45:11,400
of self-driving cars including the self-driving 
application at the end of this year or I guess  

846
01:45:11,400 --> 01:45:17,200
beginning of next year we will be shipping in 
Mercedes and then shortly after that jlr and  

847
01:45:17,200 --> 01:45:23,320
so these autonomous robotic systems are software 
defined they take a lot of work to do has computer  

848
01:45:23,320 --> 01:45:29,000
vision has obviously artificial intelligence 
control and planning all kinds of very complicated  

849
01:45:29,000 --> 01:45:35,240
technology and takes years to refine we're 
building the entire stack however we open up our  

850
01:45:35,240 --> 01:45:39,640
entire stack for all of the automotive industry 
this is just the way we work the way we work in  

851
01:45:39,640 --> 01:45:43,480
every single industry we try to build as much of 
it as we can so that we understand it but then  

852
01:45:43,480 --> 01:45:49,080
we open it up so everybody can access it whether 
you would like to buy just our computer which is  

853
01:45:49,080 --> 01:46:00,560
the world's only full functional save asld system 
that can run AI this functional safe asld quality  

854
01:46:00,560 --> 01:46:07,720
computer or the operating system on top or of 
course our data centers which is in basically  

855
01:46:07,720 --> 01:46:13,880
every AV company in the world however you would 
like to enjoy it we're delighted by it today we're  

856
01:46:13,880 --> 01:46:21,280
announcing that byd the world's largest ev company 
is adopting our next Generation it's called Thor  

857
01:46:21,280 --> 01:46:27,680
Thor is designed for Transformer engines Thor 
our next Generation AV computer will be used by

858
01:46:27,680 --> 01:46:42,480
byd you probably don't know this fact that we 
have over a million robotics developers we created  

859
01:46:42,480 --> 01:46:47,400
Jetson this robotics computer we're so proud of 
it the amount of software that goes on top of it  

860
01:46:47,400 --> 01:46:52,680
is insane but the reason why we can do it at all 
is because it's 100% Cuda compatible everything  

861
01:46:52,680 --> 01:46:58,520
that we do everything that we do in our company 
is in service of our developers and by us being  

862
01:46:58,520 --> 01:47:04,200
able to maintain this Rich ecosystem and make 
it compatible with everything that you access  

863
01:47:04,200 --> 01:47:09,760
from us we can bring all of that incredible 
capability to this little tiny computer we  

864
01:47:09,760 --> 01:47:17,120
call Jetson a robotics computer we also today 
are announcing this incredibly Advanced new SDK  

865
01:47:17,120 --> 01:47:26,240
we call it Isaac perceptor Isaac perceptor most 
most of the Bots today are pre-programmed they're  

866
01:47:26,240 --> 01:47:31,400
either following rails on the ground digital rails 
or theyd be following April tags but in the future  

867
01:47:31,400 --> 01:47:35,600
they're going to have perception and the reason 
why you want that is so that you could easily  

868
01:47:35,600 --> 01:47:40,720
program it you say would you like to go from 
point A to point B and it will figure out a way  

869
01:47:40,720 --> 01:47:48,320
to navigate its way there so by only programming 
waypoints the entire route could be adaptive the  

870
01:47:48,320 --> 01:47:51,960
entire environment could be reprogrammed just 
as I showed you at the very beginning with the  

871
01:47:51,960 --> 01:48:00,120
warehouse you can't do that with pre-programmed 
agvs if those boxes fall down they just all gum  

872
01:48:00,120 --> 01:48:06,520
up and they just wait there for somebody to come 
clear it and so now with the Isaac perceptor  

873
01:48:06,520 --> 01:48:13,360
we have incredible state-of-the-art Vision 
odometry 3D reconstruction and in addition  

874
01:48:13,360 --> 01:48:18,080
to 3D reconstruction depth perception the reason 
for that is so that you can have two modalities  

875
01:48:18,080 --> 01:48:26,080
to keep an eye on what's happening in the world 
Isaac perceptor the most used robot today is the  

876
01:48:26,080 --> 01:48:32,600
manipulator manufacturing arms and they are also 
pre-programmed the computer vision algorithms the  

877
01:48:32,600 --> 01:48:38,760
AI algorithms the control and path planning 
algorithms that are geometry aware incredibly  

878
01:48:38,760 --> 01:48:45,320
computational intensive we have made these Cuda 
accelerated so we have the world's first Cuda  

879
01:48:45,320 --> 01:48:51,760
accelerated motion planner that is geometry aware 
you put something in front of it it comes up with  

880
01:48:51,760 --> 01:48:58,520
a new plan and our articulates around it it has 
excellent perception for pose estimation of a 3D  

881
01:48:58,520 --> 01:49:06,320
object not just not it's pose in 2D but it's pose 
in 3D so it has to imagine what's around and how  

882
01:49:06,320 --> 01:49:15,000
best to grab it so the foundation pose the grip 
foundation and the um articulation algorithms  

883
01:49:15,000 --> 01:49:22,760
are now available we call it Isaac manipulator and 
they also uh just run on nvidia's computers we are  

884
01:49:22,760 --> 01:49:29,160
are starting to do some really great work in the 
next generation of Robotics the next generation  

885
01:49:29,160 --> 01:49:36,720
of Robotics will likely be a humanoid robotics 
we now have the Necessary Technology and as I  

886
01:49:36,720 --> 01:49:44,760
was describing earlier the Necessary Technology 
to imagine generalized human robotics in a way  

887
01:49:44,760 --> 01:49:50,720
human robotics is likely easier and the reason 
for that is because we have a lot more imitation  

888
01:49:50,720 --> 01:49:55,640
training data that we can provide there robots 
because we are constructed in a very similar  

889
01:49:55,640 --> 01:50:00,840
way it is very likely that the human robotics 
will be much more useful in our world because  

890
01:50:00,840 --> 01:50:06,400
we created the world to be something that we can 
interoperate in and work well in and the way that  

891
01:50:06,400 --> 01:50:11,200
we set up our workstations and Manufacturing 
and Logistics they were designed for for humans  

892
01:50:11,200 --> 01:50:17,080
they were designed for people and so these human 
robotics will likely be much more productive to  

893
01:50:17,080 --> 01:50:23,920
deploy while we're creating just like we're doing 
with the others the entire stack starting from the  

894
01:50:23,920 --> 01:50:32,920
top a foundation model that learns from watching 
video human IM human examples it could be in video  

895
01:50:32,920 --> 01:50:39,720
form it could be in virtual reality form we then 
created a gym for it called Isaac reinforcement  

896
01:50:39,720 --> 01:50:47,120
learning gym which allows the humanoid robot to 
learn how to adapt to the physical world and then  

897
01:50:47,120 --> 01:50:52,240
an incredible computer the same computer that's 
going to go into a robotic car this computer  

898
01:50:52,240 --> 01:50:58,760
will run inside a human or robot called Thor 
it's designed for Transformer engines we've  

899
01:50:58,760 --> 01:51:03,840
combined several of these into one video this is 
something that you're going to really love take a

900
01:51:03,840 --> 01:51:17,440
look it's not enough for humans 
to [Music] imagine we have to

901
01:51:17,440 --> 01:51:26,720
invent and explore real and push 
Beyond what's been done fair amount of

902
01:51:26,720 --> 01:51:35,000
detail we create smarter and

903
01:51:35,000 --> 01:51:41,840
faster we push it to fail so it can

904
01:51:41,840 --> 01:51:52,520
learn we teach it then help it teach 
itself we broaden its understanding

905
01:51:55,440 --> 01:51:56,360
to take on new

906
01:51:56,360 --> 01:52:01,200
challenges with absolute

907
01:52:01,200 --> 01:52:11,160
precision and succeed we make it perceive and

908
01:52:11,160 --> 01:52:15,120
move and even

909
01:52:15,120 --> 01:52:22,480
reason so it can share our world with us

910
01:52:22,480 --> 01:52:41,400
[Music]
1:52:22.520,1193:02:47.295
[Music]

911
01:52:41,400 --> 01:52:48,920
this is where inspiration leads us the 
next Frontier this is Nvidia Project

912
01:52:48,920 --> 01:53:00,800
Groot a general purpose Foundation model for 
humanoid robot learning the group model takes  

913
01:53:00,800 --> 01:53:06,880
multimodal instructions and past interactions 
as input and produces the next action for the  

914
01:53:06,880 --> 01:53:14,720
robot to execute we developed Isaac lab a 
robot learning application to train gr on  

915
01:53:14,720 --> 01:53:22,200
Omniverse Isaac Sim and we scale out with osmo a 
new compute orchestration service that coordinates  

916
01:53:22,200 --> 01:53:30,280
work flows across dgx systems for training and 
ovx systems for simulation with these tools we  

917
01:53:30,280 --> 01:53:37,800
can train Groot in physically based simulation 
and transfer zero shot to the real world the  

918
01:53:37,800 --> 01:53:43,680
Groot model will enable a robot to learn from a 
handful of human demonstrations so it can help  

919
01:53:43,680 --> 01:53:53,640
with everyday tasks and emulate human movement 
just by observing us this is made possible  

920
01:53:53,640 --> 01:53:59,440
with nvidia's technologies that can understand 
humans from videos train models and simulation  

921
01:53:59,440 --> 01:54:05,840
and ultimately deploy them directly to physical 
robots connecting group to a large language model  

922
01:54:05,840 --> 01:54:12,320
even allows it to generate motions by following 
natural language instructions hi go1 can you give  

923
01:54:12,320 --> 01:54:22,360
me a high five sure thing let's high five can 
you give us some cool moves sure check this out

924
01:54:25,120 --> 01:54:29,160
all this incredible intelligence is 
powered by the new Jetson Thor robotics  

925
01:54:29,160 --> 01:54:35,800
chips designed for Groot built for the 
future with Isaac lab osmo and Groot  

926
01:54:35,800 --> 01:54:39,760
we're providing the building blocks 
for the next generation of AI powered

927
01:54:39,760 --> 01:54:46,040
[Applause]

928
01:54:46,040 --> 01:54:52,320
robotics [Music]

929
01:54:56,400 --> 01:54:57,120
about the same

930
01:54:57,120 --> 01:55:11,280
size the soul of Nvidia the intersection 
of computer Graphics physics artificial  

931
01:55:11,280 --> 01:55:18,160
intelligence it all came to bear at this moment 
the name of that project general robotics

932
01:55:18,160 --> 01:55:33,120
003 I know super good super good well 
I think we have some special guests do

933
01:55:33,120 --> 01:55:43,280
[Music] we hey

934
01:55:43,280 --> 01:55:51,080
guys so I understand you guys 
are powered by Jetson they're  

935
01:55:51,080 --> 01:55:58,600
powered by Jetson little Jetson robotics 
computers inside they learn to walk in Isaac

936
01:55:58,600 --> 01:56:07,120
Sim ladies and gentlemen this this is orange and  

937
01:56:07,120 --> 01:56:15,840
this is the famous green they are the 
bdx robots of Disney amazing Disney

938
01:56:15,840 --> 01:56:25,280
research come on you guys let's wrap 
up let's go five things where you

939
01:56:25,280 --> 01:56:29,240
going I sit right

940
01:56:29,240 --> 01:56:36,520
here Don't Be Afraid come here green hurry

941
01:56:36,520 --> 01:56:47,560
up what are you saying no it's 
not time to eat it's not time

942
01:56:47,560 --> 01:56:58,120
to I'll I'll give you a snack in a moment let 
me finish up real quick come on green hurry up  

943
01:56:58,120 --> 01:57:08,920
stop wasting time five things five things first 
a new Industrial Revolution every data center  

944
01:57:08,920 --> 01:57:14,720
should be accelerated a trillion dollars worth 
of installed data centers will become modernized  

945
01:57:14,720 --> 01:57:17,960
over the next several years second because 
of the computational capability we brought  

946
01:57:17,960 --> 01:57:24,360
to bear a new way of doing software has emerged 
generative AI which is going to create new in new  

947
01:57:24,360 --> 01:57:31,320
infrastructure dedicated to doing one thing and 
one thing only not for multi-user data centers but  

948
01:57:31,320 --> 01:57:39,480
AI generators these AI generation will create 
incredibly valuable software a new Industrial  

949
01:57:39,480 --> 01:57:46,400
Revolution second the computer of this revolution 
the computer of this generation generative AI  

950
01:57:46,400 --> 01:57:54,520
trillion parameters blackw insane amounts of 
computers and computing third I'm trying to

951
01:57:54,520 --> 01:58:05,440
concentrate good job third new computer new 
computer creates new types of software new  

952
01:58:05,440 --> 01:58:10,240
type of software should be distributed in a 
new way so that it can on the one hand be an  

953
01:58:10,240 --> 01:58:15,760
endpoint in the cloud and easy to use but still 
allow you to take it with you because it is your  

954
01:58:15,760 --> 01:58:20,440
intelligence your intelligence should be pack 
packaged up in a way that allows you to take  

955
01:58:20,440 --> 01:58:25,840
it with you we call them Nims and third 
these Nims are going to help you create a  

956
01:58:25,840 --> 01:58:30,560
new type of application for the future not 
one that you wrote completely from scratch  

957
01:58:30,560 --> 01:58:37,280
but you're going to integrate them like teams 
create these applications we have a fantastic  

958
01:58:37,280 --> 01:58:44,920
capability between Nims the AI technology the 
tools Nemo and the infrastructure dgx cloud in  

959
01:58:44,920 --> 01:58:49,360
our AI Foundry to help you create proprietary 
applications proprietary chat Bots and then  

960
01:58:49,360 --> 01:58:53,840
lastly everything that moves in the future 
will be robotic you're not going to be the  

961
01:58:53,840 --> 01:59:02,480
only one and these robotic systems whether they 
are humanoid amrs self-driving cars forklifts  

962
01:59:02,480 --> 01:59:09,800
manipulating arms they will all need one thing 
Giant stadiums warehouses factories there can to  

963
01:59:09,800 --> 01:59:14,080
be factories that are robotic orchestrating 
factories uh manufacturing lines that are  

964
01:59:14,080 --> 01:59:22,120
robotics building cars that are robotics these 
systems all need one thing they need a platform  

965
01:59:22,120 --> 01:59:27,880
a digital platform a digital twin platform and 
we call that Omniverse the operating system of  

966
01:59:27,880 --> 01:59:34,360
the robotics World these are the five things that 
we talked about today what does Nvidia look like  

967
01:59:34,360 --> 01:59:39,160
what does Nvidia look like when we talk about 
gpus there's a very different image that I have  

968
01:59:39,160 --> 01:59:44,480
when I when people ask me about gpus first I see 
a bunch of software stacks and things like that  

969
01:59:44,480 --> 01:59:52,040
and second I see this this is what we announce 
to you today this is Blackwell this is the plat

970
01:59:57,560 --> 02:00:05,080
amazing amazing processors MV link switches 
networking systems and the system design is  

971
02:00:05,080 --> 02:00:10,680
a miracle this is Blackwell and this 
to me is what a GPU looks like in my

972
02:00:10,680 --> 02:00:23,480
mind listen orange green I think we 
have one more treat for everybody  

973
02:00:23,480 --> 02:00:29,840
what do you think should we okay we 
have one more thing to show you roll

974
02:00:29,840 --> 02:00:40,880
[Music]

975
02:00:40,880 --> 02:00:51,920
it

976
02:00:51,920 --> 02:00:51,960
[Music]

977
02:00:51,960 --> 02:01:05,880
[Music]

978
02:01:05,880 --> 02:01:21,880
he

979
02:01:21,880 --> 02:01:36,600
[Music]
2:01:21.920,1193:02:47.295
[Music]

980
02:01:36,600 --> 02:01:51,840
[Music] m

981
02:01:51,840 --> 02:02:21,880
[Music] yeah [Music]

982
02:02:21,880 --> 02:02:46,120
[Music]

983
02:02:46,120 --> 02:02:54,200
thank you thank you have a great have a 
great GTC thank you all for coming thank

984
02:02:54,200 --> 02:03:04,800
you

